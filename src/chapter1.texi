@chapter Построение абстракций с помощью процедур
@node    Chapter 1, Chapter 2, Acknowledgments, Top

@quotation
Действия, в которых ум проявляет свои способности в отношении своих простых
идей, суть главным образом следующие три: 1. Соединение нескольких простых
идей в одну сложную; так образовались все сложные идеи,  2. Сведение вместе
двух идей, все равно, простых или сложных, и сопоставление их друг с другом
так, чтобы обозревать их сразу, но не соединять в одну; так ум приобретает все
свои идеи отношений, 3. Обособление идей от всех других идей, сопутствующих
им в реальной действительности; это действие называется абстрагированием, и
при его помощи образованы все общие идеи в уме.

---John Locke, @emph{An Essay Concerning Human Understanding} (1690)
@end quotation

@c @sp 1.0

@noindent
\lettrine[findent=1pt]{М}{ы собираемся изучать} понятие @newterm{computational
processes} (вычислительный процесс). Вычислительные процессы - это абстрактные
существа, которые живут в компьютерах. Развиваясь, процессы манипулируют
абстракциями другого типа, которые называются @newterm{data} (данные). Эволюция
процесса направляется набором правил, называемым @newterm{prorgam} (программа).
В сущности, мы заколдовываем духов компьютера с помощью своих чар.

Вычислительные процессы и вправду вполне соответствуют представлениям
колдуна о ду́хах. Их нельзя увидеть или потрогать. Они вообще сделаны не
из вещества. В то же время они совершенно реальны. Они могут выполнять
умственную работу, могут отвечать на вопросы. Они способны
воздействовать на внешний мир, оплачивая счета в банке или управляя
рукой робота на заводе. Программы, которыми мы пользуемся для заклинания
процессов, похожи на чары колдуна. Они тщательно составляются из
символических выражений на сложных и немногим известных @newterm{programming
languages} (языках программирования), описывающих задачи, которые мы хотим
поручить процессам.

На исправно работающем компьютере вычислительный процесс выполняет программы
точно и безошибочно. Таким образом, подобно ученику чародея, программисты-
новички должны научиться понимать и предсказывать последствия своих заклинаний.
Даже мелкие ошибки (их обычно называют @newterm{bugs} (блохами) или
@newterm{glitches} (глюками), могут привести к сложным и непредсказуемым
последствиям.

К счастью, обучение программированию не так опасно, как обучение колдовству,
поскольку духи, с которыми мы имеем дело, надежно связаны. В то же время
программирование в реальном мире требует осторожности, профессионализма и
мудрости. Например, мелкая ошибка в программе автоматизированного проектирования
может привести к катастрофе самолета, прорыву плотины или самоуничтожению
промышленного робота.

Специалисты по программному обеспечению умеют организовывать программы так,
чтобы быть потом обоснованно уверенными: получившиеся процессы будут выполнять
те задачи, для которых они предназначены. Они могут изобразить поведение
системы заранее.  Они знают, как построить программу так, чтобы непредвиденные
проблемы не привели к катастрофическим последствиям, а когда эти проблемы
возникают, программисты умеют @newterm{debugging} (отлаживать) свои программы.
Хорошо спроектированные вычислительные системы, подобно хорошо спроектированным
автомобилям или ядерным реакторам, построены модульно, так что их части могут
создаваться, заменяться и отлаживаться по отдельности.

@subsubheading Программирование на Лиспе

Для описания процессов нам нужен подходящий язык, и с этой целью мы
используем язык программирования Лисп. Точно так же, как обычные наши
мысли чаще всего выражаются на естественном языке (например, английском,
французском или японском), а описания количественных явлений выражаются
языком математики, наши процедурные мысли будут выражаться на Лиспе.
Лисп был изобретен в конце 1950-х как формализм для рассуждений об
определенном типе логических выражений, называемых @newterm{recursion
equations}, как о модели вычислений. Язык был придуман Джоном Маккарти
и основывается на его статье <<Рекурсивные функции над символьными
выражениями и их вычисление с помощью машины>> (McCarthy 1960).

Несмотря на то, что Лисп возник как математический формализм, это
практический язык программирования. @newterm{interpreter} Лиспа представляет
собой машину, которая выполняет процессы, описанные на языке Лисп.
Первый интерпретатор Лиспа написал сам Маккарти с помощью коллег и
студентов из Группы по Искусственному Интеллекту Исследовательской
лаборатории по Электронике MIT и Вычислительного центра.
@acronym{MIT} @footnote{ @cite{Руководство программиста по Лиспу 1} появилось в
1960 году, а @cite{Руководство программиста по Лиспу 1.5} (@ref{McCarthy
1965}) в 1962 году. Ранняя история Лиспа описана в (@ref{McCarthy 1978}).}.
Лисп, чье название происходит от сокращения английских слов LISt
Processing (обработка списков), был создан с целью обеспечить
возможность символьной обработки для решения таких программистских
задач, как символьное дифференцирование и интегрирование алгебраических
выражений. С этой целью он содержал новые объекты данных, известные под
названием атомов и списков, что резко отличало его от других языков
того времени.

Лисп не был результатом срежиссированного проекта. Он развивался
неформально, экспериментальным путем, с учетом запросов
пользователей и прагматических соображений реализации. Неформальная
эволюция Лиспа продолжалась долгие годы, и сообщество пользователей
Лиспа традиционно отвергало попытки провозгласить какое-либо
<<официальное>> описание языка. Вместе с гибкостью и изяществом
первоначального замысла такая эволюция позволила Лиспу, который сейчас
по возрасту второй из широко используемых языков (старше только
Фортран), непрерывно адаптироваться и вбирать в себя наиболее
современные идеи о проектировании программ. Таким образом, сегодня Лисп
представляет собой семью диалектов, которые, хотя и разделяют большую
часть изначальных свойств, могут существенным образом друг от друга
отличаться. Тот диалект, которым мы пользуемся в этой книге, называется
Scheme (Схема). @footnote{Большинство крупных Лисп-программ 1970х, были
написаны на одном из двух диалектов: MacLisp (@ref{Moon 1978}; @ref{Pitman 1983}),
разработанный в рамках проекта @acronym{MAC} в @acronym{MIT}, и InterLisp 
(@ref{Teitelman 1974}), разработанный в компании <<Болт, Беранек и Ньюман>>
и в Исследовательском центре компании Xerox в Пало Альто. Диалект Portable
Standard Lisp (Переносимый Стандартный Лисп, (@ref{Hearn 1969}; @ref{Griss 1981})
был спроектирован так, чтобы его легко было переносить на разные машины.
MacLisp породил несколько поддиалектов, например Franz Lisp,
разработанный в Калифорнийском университете в Беркли, и Zetalisp
(@ref{Moon and Weinreb 1981}), который основывался на специализированном процессоре,
спроектированном в лаборатории Искусственного Интеллекта в @acronym{MIT} для
наиболее эффективного выполнения программ на Лиспе. Диалект Лиспа,
используемый в этой книге, называется Scheme (@ref{Steele and Sussman 1975}).
Он был изобретен в 1975 году Гаем Льюисом Стилом мл. и Джеральдом Джеем
Сассманом в лаборатории Искусственного Интеллекта @acronym{MIT}, а затем заново
реализован для использования в учебных целях в @acronym{MIT}. Scheme стала
стандартом @acronym{IEEE} в 1990 году (@ref{IEEE 1900}). Диалект Common Lisp
(@ref{Steele 1982}; @ref{Steele 1990}) был специально разработан Лисп-
сообществом так, чтобы сочетать свойства более ранних диалектов Лиспа и стать
промышленным стандартом Лиспа. Common Lisp стал стандартом @acronym{ANSI} в 1994 году
(@ref{ANSI 1994})}.

Из-за своего экспериментального характера и внимания к символьной
обработке первое время Лисп был весьма неэффективен при решении
вычислительных задач, по крайней мере по сравнению с Фортраном. Однако
за прошедшие годы были разработаны компиляторы Лиспа, которые переводят
программы в машинный код, способный производить численные вычисления с
разумной эффективностью. А для специализированных приложений Лисп
удавалось использовать весьма эффективно. @footnote{Одним из таких
приложений был пионерский эксперимент, имевший научное значение ---
интегрирование движения Солнечной системы, которое превосходило по
точности предыдущие результаты примерно на два порядка и
продемонстрировало, что динамика Солнечной системы хаотична. Это
вычисление стало возможным благодаря новым алгоритмам интегрирования,
специализированному компилятору и специализированному компьютеру;
причем все они были реализованы с помощью программных средств,
написанных на Лиспе (@ref{Abelson et al. 1992}; @ref{Sussman and Wisdom 1992})}.
Хотя Лисп и не преодолел пока свою старую репутацию безнадежно
медленного языка, в наше время он используется во многих приложениях,
где эффективность не является главной заботой. Например, Лисп стал
любимым языком для оболочек операционных систем, а также в качестве
языка расширения для редакторов и систем автоматизированного
проектирования.

\enlargethispage{\baselineskip}

Но коль скоро Лисп не похож на типичные языки, почему же мы тогда
используем его как основу для нашего разговора о программировании?
Потому что этот язык обладает уникальными свойствами, которые делают его
замечательным средством для изучения важнейших конструкций
программирования и структур данных, а также для соотнесения их с
деталями языка, которые их поддерживают. Самое существенное из этих
свойств --- то, что лисповские описания процессов, называемые
(procedures), сами по себе могут представляться и обрабатываться как
данные Лиспа. Важность этого в том, что существуют мощные методы
проектирования программ, которые опираются на возможность сгладить
традиционное различение <<пассивных>> данных и <<активных>> процессов.
Как мы обнаружим, способность Лиспа рассматривать процедуры в качестве
данных делает его одним из самых удобных языков для исследования этих
методов. Способность представлять процедуры в качестве данных делает
Лисп еще и замечательным языком для написания программ, которые должны
манипулировать другими программами в качестве данных, таких как
интерпретаторы и компиляторы, поддерживающие компьютерные языки. А
помимо и превыше всех этих соображений, писать программы на Лиспе ---
громадное удовольствие.

@menu
* 1-1::              Элементы программирования
* 1-2::              Процедуры и порождаемые ими процессы
* 1-3::              Формулирование абстракций с помощью процедур высших порядков
@end menu

@section Элементы программирования
@node	1.1, 1.2, Глава 1, Глава 1

Мощный язык программирования --- это нечто большее. чем просто
средство, с помощью которого можно учить компьютер решать задачи. Язык
также служит средой, в которой мы организуем свое мышление о
процессах. Таким образом, когда мы описываем язык, мы должны уделять
особое внимание тем средствам, которые в нем имеются для того, чтобы
комбинировать простые понятия и получать из них сложные. Всякий язык
программирования обладает тремя предназначенными для этого механизмами:

@itemize @bullet

@item @b{элементарные выражения},
представляющие минимальные сущности, с которыми язык имеет дело;

@item @b{средства комбинирования},
с помощью которых из простых объектов составляются сложные;

@item @b{средства абстракции},
с помощью которых сложные объекты можно называть и обращаться с ними
как с единым целым.

@end itemize

@noindent
В программировании мы имеем дело с двумя типами объектов:
процедурами и данными. (Впоследствии мы обнаружим, что на самом деле
большой разницы между ними нет.) Говоря неформально, данные --- это
<<материал@math{\kern0.1em}>>, который мы хотим обрабатывать, а процедуры 
--- это описания правил обработки данных. Таким образом, от любого мощного
языка программирования требуется способность описывать простые данные и
элементарные процедуры, а также наличие средств комбинирования и
абстракции процедур и данных.

В этой главе мы будем работать только с простыми численными данными,
так что мы сможем сконцентрировать внимание на правилах построения
процедур.@footnote{Называть числа <<простыми данными>> --- это
бесстыдный блеф. На самом деле работа с числами является одной из самых
сложных и запутанных сторон любого языка программирования. Вот некоторые
из возникающих при этом вопросов: Некоторые компьютеры отличают
@newterm{integers}, вроде 2, от @newterm{real numbers}, вроде 2.71.
Отличается ли вещественное число 2.00 от целого 2? Используются ли одни и те
же арифметические операции для целых и для вещественных чисел? Что
получится, если 6 поделить на 2: 3 или 3.0? Насколько большие числа мы
можем представить? Сколько десятичных цифр после запятой мы можем
хранить? Совпадает ли диапазон целых чисел с диапазоном вещественных? И
помимо этих вопросов, разумеется, существует множество проблем,
связанных с ошибками округления --- целая наука численного анализа.
Поскольку в этой книге мы говорим о проектировании больших программ, а
не о численных методах, все эти проблемы мы будем игнорировать.
Численные примеры в этой главе будут демонстрировать такое поведение
при округлении, какое можно наблюдать, если использовать арифметические
операции, сохраняющие при работе с вещественными числами ограниченное
число десятичных цифр после запятой.}. В последующих главах мы увидим,
что те же самые правила позволяют нам строить процедуры для работы со
сложными данными.

@menu
* 1-1-1::            Выражения
* 1-1-2::            Имена и окружение
* 1-1-3::            Вычисление комбинаций
* 1-1-4::            Составные процедуры
* 1-1-5::            Подстановочная модель применения процедуры
* 1-1-6::            Условные выражения и предикаты
* 1-1-7::            Пример вычисление квадратного корня методом Ньютона
* 1-1-8::            Процедуры как абстракции типа <<черный ящик>>
@end menu

@subsection Выражения
@node	1.1.1, 1.1.2, 1.1, 1.1

Самый простой способ начать обучение программированию --- рассмотреть
несколько типичных примеров работы с интерпретатором диалекта Лиспа
Scheme. Представьте, что Вы сидите за терминалом компьютера. Вы
печатаете @newterm{expression}, а интерпретатор отвечает, выводя результат
@newterm{evaluation} этого выражения.

Один из типов элементарных выражений, которые Вы можете вводить --- это
числа. (Говоря точнее, выражение, которое Вы печатаете, состоит из цифр,
представляющих число по основанию 10.) Если Вы дадите Лиспу число

@lisp
486
@end lisp

@noindent
интерпретатор ответит Вам, напечатав@footnote{Здесь и далее, когда нам
нужно будет подчеркнуть разницу между вводом, который набирает на
терминале пользователь, и выводом, который производит компьютер, мы
будем изображать последний наклонным шрифтом.}

@lisp
@i{486}
@end lisp

@noindent

Выражения, представляющие числа, могут сочетаться с выражением,
представляющим элементарную процедуру (скажем, @code{+} или @code{*}),
так что получается составное выражение, представляющее собой применение
процедуры к этим числам. Например:

@lisp
(+ 137 349)
@i{486}
@end lisp

@lisp
(- 1000 334)
@i{666}
@end lisp

@lisp
(* 5 99)
@i{495}
@end lisp

@lisp
(/ 10 5)
@i{2}
@end lisp

@lisp
(+ 2.7 10)
@i{12.7}
@end lisp

@noindent
Выражения такого рода, образуемые путем заключения списка выражений в
скобки с целью обозначить применение функции к аргументам, называются
@newterm{combinations}. Самый левый элемент в списке называется @newterm{operator}, а
остальные элементы --- @newterm{operands}. Значение комбинации вычисляется
путем применения процедуры, задаваемой оператором, к @newterm{arguments},
которые являются значениями операндов.

Соглашение, по которому оператор ставится слева от операндов, известно
как @newterm{prefix notation}, и поначалу оно может сбивать с толку, поскольку
существенно отличается от общепринятой математической записи. Однако у
префиксной нотации есть несколько преимуществ. Одно из них состоит в
том, что префиксная запись может распространяться на процедуры с
произвольным количеством аргументов, как в следующих примерах:

@lisp
(+ 21 35 12 7)
@i{75}
@end lisp

@lisp
(* 25 4 12)
@i{1200}
@end lisp

@noindent
Не возникает никакой неоднозначности, поскольку оператор всегда
находится слева, а вся комбинация ограничена скобками.

Второе преимущество префиксной нотации состоит в том, что она
естественным образом расширяется, позволяя комбинациям @i{nested} друг в
друга, то есть допускает комбинации, элементы которых сами являются
комбинациями:

@lisp
(+ (* 3 5) (- 10 6))
@i{19}
@end lisp

@noindent
Не существует (в принципе) никакого предела для глубины такого
вложения и общей сложности выражений, которые может вычислять
интерпретатор Лиспа. Это мы, люди, путаемся даже в довольно простых
выражениях, например

@lisp
(+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6))
@end lisp

@noindent
а интерпретатор с готовностью вычисляет его и дает ответ 57. Мы можем
облегчить себе задачу, записывая такие выражения в форме

@lisp
(+ (* 3
      (+ (* 2 4)
         (+ 3 5)))
   (+ (- 10 7)
      6))
@end lisp

@noindent
Эти правила форматирования называются @newterm{pretty printing}. Согласно им,
всякая длинная комбинация записывается так, чтобы ее операнды
выравнивались вертикально. Получающиеся отступы ясно показывают
структуру выражения.@footnote{Как правило, Лисп-системы содержат
средства, которые помогают пользователям форматировать выражения.
Особенно удобны две возможности: сдвигать курсор на правильную позицию
для красивой печати каждый раз, когда начинается новая строка и
подсвечивать нужную левую скобку каждый раз, когда печатается правая.}

Даже работая со сложными выражениями, интерпретатор всегда ведет себя
одинаковым образом: он считывает выражение с терминала, вычисляет его и
печатает результат. Этот способ работы иногда называют @newterm{read-eval-print
loop}. Обратите особое внимание на то, что не нужно специально просить
интерпретатор напечатать значение выражения.@footnote{Лисп следует
соглашению, что у всякого выражения есть значение. Это соглашение,
вместе со старой репутацией Лиспа как неэффективного языка, послужило
источником остроумного замечания Алана Перлиса (парафразы из Оскара
Уайльда), что <<Программисты на Лиспе знают значение всего на свете, но
ничему не знают цену>>.}

@subsection Имена и окружение
@node	1.1.2, 1.1.3, 1.1.1, 1.1

Одна из важнейших характеристик языка программирования --- какие в нем
существуют средства использования имен для указания на вычислительные
объекты. Мы говорим, что имя обозначает @newterm{variable}, чьим @newterm{value}
является объект.

В диалекте Лиспа Scheme мы даем вещам имена с помощью слова
@code{define}. Предложение

@lisp
(define size 2)
@end lisp

@noindent
заставляет интерпретатор связать значение 2 с именем
@code{size}.@footnote{Мы не печатаем в этой книге ответы интерпретатора
при вычислении определений, поскольку они зависят от конкретной
реализации языка.} После того, как имя @code{size} связано со значением
2, мы можем указывать на значение 2 с помощью имени:

@lisp
size
@i{2}
@end lisp

@lisp
(* 5 size)
@i{10}
@end lisp

@noindent
Вот еще примеры использования @code{define}:

@lisp
(define pi 3.14159)
(define radius 10)
(* pi (* radius radius))
@i{314.159}
(define circumference (* 2 pi radius))
circumference
@i{62.8318}
@end lisp

@noindent
Слово @code{define} служит в нашем языке простейшим средством
абстракции, поскольку оно позволяет нам использовать простые имена для
обозначения результатов сложных операций, как, например, вычисленная
только что длина окружности --- @code{circumference}. Вообще говоря,
вычислительные объекты могут быть весьма сложными структурами, и было
бы очень неудобно, если бы нам приходилось вспоминать и повторять все
их детали каждый раз, когда нам захочется их использовать. На самом деле
сложные программы конструируются методом построения шаг за шагом
вычислительных объектов возрастающей сложности. Интерпретатор делает
такое пошаговое построение программы особенно удобным, поскольку связи
между именами и объектами могут создаваться последовательно по мере
взаимодействия программиста с компьютером. Это свойство интерпретаторов
облегчает пошаговое написание и тестирование программ, и во многом
благодаря именно ему получается так, что программы на Лиспе обычно
состоят из большого количества относительно простых процедур.

Ясно, что раз интерпретатор способен ассоциировать значения с
символами и затем вспоминать их, то он должен иметь некоторого рода
память, сохраняющую пары имя-объект. Эта память называется @newterm{environment}
(а точнее, @newterm{global environment}, поскольку позже мы увидим, что
вычисление может иметь дело с несколькими окружениями).@footnote{ В
главе @ref{Chapter 3} мы увидим, что понятие окружения необходимо как для понимания работы
интерпретаторов, так и для их реализации.}

@comment @subsection Evaluating Combinations
@subsection Вычисление комбинаций
@node	1.1.3, 1.1.4, 1.1.2, 1.1
Одна из наших целей в этой главе --- выделить элементы процедурного
мышления. Рассуждая в этом русле, примем во внимание, что
интерпретатор, вычисляя значение комбинации, тоже следует процедуре:

Чтобы вычислить комбинацию, требуется:

@enumerate 1

@item
Вычислить все подвыражения комбинации.

@item
Применить процедуру, которая является значением самого левого
подвыражения (оператора) к аргументам --- значениям остальных
подвыражений (операндов).

@end enumerate

@noindent
Даже в этом простом правиле видны несколько важных свойств процессов в
целом. Прежде всего, заметим, что на первом шаге для того, чтобы
провести процесс вычисления для комбинации, нужно сначала проделать
процесс вычисления для каждого элемента комбинации. Таким образом,
правило вычисления (recursive) по своей природе; это означает, что в
качестве одного из своих шагов оно включает применение того же самого
правила.@footnote{Может показаться странным, что правило вычисления
предписывает нам в качестве части первого шага вычислить самый левый
элемент комбинации, --- ведь до сих пор это мог быть только оператор
вроде @code{+} или @code{*}, представляющий встроенную процедуру,
например, сложение или умножение. Позже мы увидим, что полезно иметь
возможность работать и с комбинациями, чьи операторы сами по себе
являются составными выражениями.}

Заметьте, какую краткость понятие рекурсии придает описанию того, что в
случае комбинации с глубоким вложением выглядело бы как достаточно
сложный процесс. Например, чтобы вычислить

@lisp
(* (+ 2 (* 4 6))
   (+ 3 5 7))
@end lisp

@noindent
требуется применить правило вычисления к четырем различным комбинациям.
Картину этого процесса можно получить, нарисовав комбинацию в виде
дерева, как показано на рис. @ref{Рисунок 1.1}. Каждая комбинация
представляется в видевершины, а ее оператор и операнды --- в виде
ветвей, исходящих из этой вершины. Концевые вершины (то есть те, из
которых не исходит ни одной ветви) представляют операторы или числа.
Рассматривая вычисление как дерево, мы можем представить себе, что
значения операндов распространяются от концевых вершин вверх и затем
комбинируются на все более высоких уровнях. Впоследствии мы увидим, что
рекурсия --- это вообще очень мощный метод обработки иерархических,
древовидных объектов. На самом деле форма правила вычисления
<<распространить значения наверх>> является примером общего типа
процессов, известного как @newterm{tree accumulation}.

@float
@quotation
@anchor{Рисунок 1.1}
@ifinfo
@strong{Рисунок 1.1:} Вычисление, πредставленное в виде дерева.

@example
   390
   /|\____________
  / |             \
 *  26            15
    /|\           /|\
   / | \         // \\
  +  2  24      / | | \
        /|\    +  3 5  7
       / | \
      *  4  6
@end example
@end ifinfo
@iftex
@sp 0.2
@center @image{fig/chap1/Fig1.1g,31mm,,,.pdf}
@sp 0.4
@caption{@strong{Рисунок 1.1:} Вычисление, πредставленное в виде дерева.}
@sp 0.7
@end iftex
@end quotation
@end float

Далее, заметим, что многократное применение первого шага приводит нас к
такой точке, где нам нужно вычислять уже не комбинации, а элементарные
выражения, а именно числовые константы, встроенные операторы или другие
имена. С этими случаями мы справляемся, положив, что:

@itemize @bullet

@item
значением числовых констант являются те числа, которые они называют;

@item
значением встроенных операторов являются последовательности машинных
команд, которые выполняют соответствующие операции; и

@item
значением остальных имен являются те объекты, с которыми эти имена
связаны в окружении.

@end itemize

@noindent
Мы можем рассматривать второе правило как частный случай третьего,
постановив, что символы вроде @code{+} и @code{*} тоже включены в
глобальное окружение и связаны с последовательностями машинных команд,
которые и есть их <<значения>>. Главное здесь --- это роль окружения
при определении значения символов в выражениях. В таком диалоговом
языке, как Лисп, не имеет смысла говорить о значении выражения, скажем,
@code{(+ x 1)}, не указывая никакой информации об окружении, которое
дало бы значение символу @code{x} (и даже символу @code{+}). Как мы
увидим в главе @ref{Глава 3}, общее понятие окружения, предоставляющего
контекст, в котором происходит вычисление, будет играть важную роль в
нашем понимании того, как выполняются программы.

Заметим, что рассмотренное нами правило вычисления не обрабатывает
определений. Например, вычисление @code{(define x 3)} не означает
применение @code{define} к двум аргументам, один из которых значение
символа @code{x}, а другой равен 3, поскольку смысл @code{define} как
раз и состоит в том, чтобы связать @code{x} со значением. (Таким
образом, @code{(define x 3)} --- не комбинация.)

Такие исключения из вышеописанного правила вычисления называются
особыми формами (@newterm{special forms}). @code{define} --- пока что
единственный встретившийся нам пример особой формы, но очень скоро мы
познакомимся и с другими. У каждой особой формы свое собственное
правило вычисления. Разные виды выражений (вместе со своими правилами
вычисления) составляют синтаксис языка программирования. По сравнению с
большинством языков программирования, у Лиспа очень простой синтаксис;
а именно, правило вычисления для выражений может быть описано как очень
простое общее правило плюс специальные правила для небольшого числа
особых форм.@footnote{Особые синтаксические формы, которые представляют
собой просто удобное альтернативное поверхностное представление для
того, что можно выразить более унифицированным способом, иногда называют
синтаксический сахар (@newterm{syntactic sugar}), используя выражение
Питера Ландина. По сравнению с пользователями других языков, программистов
на Лиспе, как правило, мало волнует синтаксический сахар. (Для контраста
возьмите руководство по Паскалю и посмотрите, сколько места там уделяется
описанию синтаксиса).  Такое презрение к синтаксису отчасти происходит
от гибкости Лиспа, позволяющего легко изменять поверхностный синтаксис,
а отчасти из наблюдения, что многие <<удобные>> синтаксические конструкции,
которые делают язык менее последовательным, приносят в конце концов больше
вреда, чем пользы, когда программы становятся большими и сложными.
По словам Алана Перлиса, <<Синтаксический сахар вызывает рак точки с
запятой>>.}

@comment @subsection Compound Procedures
@subsection Составные процедуры
@node	1.1.4, 1.1.5, 1.1.3, 1.1

Мы нашли в Лиспе некоторые из тех элементов, которые должны
присутствовать в любом мощном языке программирования:

@itemize @bullet

@item
Числа и арифметические операции представляют собой элементарные
данные и процедуры.

@item
Вложение комбинаций дает возможность комбинировать операции.

@item
Определения, которые связывают имена со значениями, дают ограниченные
возможности абстракции.

@end itemize

@noindent
Теперь мы узнаем об (@newterm{procedure definitions}) --- значительно более
мощном методе абстракции, с помощью которого составной операции можно
дать имя и затем ссылаться на нее как на единое целое.

Для начала рассмотрим, как выразить понятие <<возведения в квадрат>>.
Можно сказать так: <<Чтобы возвести что-нибудь в квадрат, нужно
умножить его само на себя>>. Вот как это выражается в нашем языке:

@lisp
(define (square x) (* x x))
@end lisp

@noindent
Это можно понимать так:

@example
(define      (square            x)      (*      x        x))
   |            |               |        |      |        |
 Чтобы  возвести в квадрат  что-либо,  умножь  это  само на себя.
@end example

@noindent
Здесь мы имеем @newterm{compound procedure}, которой мы дали имя @code{square}.
Эта процедура представляет операцию умножения чего-либо само на себя. Та
вещь, которую нужно подвергнуть умножению, получает здесь имя @code{x},
которое играет ту же роль, что в естественных языках играет
местоимение. Вычисление этого определения создает составную процедуру и
связывает ее с именем @code{square}.@footnote{Заметьте, что здесь
присутствуют две различные операции: мы создаем процедуру, и мы даем ей
имя @code{square}. Возможно, и на самом деле даже важно, разделить эти
два понятия: создавать процедуры, никак их не называя, и давать имена
процедурам, уже созданным заранее. Мы увидим, как это делается, в
разделе @ref{1.3.2}.}

Общая форма определения процедуры такова:

@lisp
(define (@math{\langle}@var{имя}@math{\kern0.03em\rangle} @math{\langle}@var{формальные-параметры}@math{\kern0.02em\rangle})
  @math{\langle\kern0.08em}@var{тело}@math{\rangle})
@end lisp

@noindent
@math{\langle}@var{имя}@math{\kern0.08em\rangle} --- это тот символ, с которым
нужно связать в окружении определение процедуры.@footnote{На всем
протяжении этой книги мы будем описывать обобщенныйсинтаксис выражений,
используя курсив в угловых скобках --- напр. @math{\langle}@var{имя}@math{\kern0.08em\rangle},
чтобы обозначить <<дырки>> в выражении, которые нужно заполнить, когда это
выражение используется в языке.}
@math{\langle}@var{формальные-параметры}@math{\kern0.08em\rangle}--- это
имена, которые в теле процедуры используются для отсылки к
соответствующим аргументам процедуры.
@math{\langle}@var{тело}@math{\kern0.08em\rangle}--- это выражение, которое
вычислит результат применения процедуры, когда формальные параметры
будут заменены аргументами, к которым процедура будет
применяться.@footnote{В более общем случае тело процедуры может быть
последовательностью выражений. В этом случае интерпретатор вычисляет по
очереди все выражения в этой последовательности и возвращает в
качестве значения применения процедуры значение последнего выражения.}
@math{\langle}@var{имя}@math{\kern0.08em\rangle} и
@math{\langle}@var{формальные-параметры}@math{\kern0.08em\rangle} заключены
в скобки, как это было бы при вызове определяемой процедуры.

Теперь, когда процедура @code{square} определена, мы можем ее
использовать:

@lisp
(square 21)
@i{441}
(square (+ 2 5))
@i{49}
(square (square 3))
@i{81}
@end lisp

@noindent
Кроме того, мы можем использовать @code{square} при определении других
процедур. Например, @math{x^2 + y^2} можно записать как

@lisp
(+ (square x) (square y))
@end lisp

@noindent
Легко можно определить процедуру @code{sum-of-squares}, которая,
получая в качестве аргументов два числа, дает в результате сумму их
квадратов:

@lisp
(define (sum-of-squares x y)
  (+ (square x) (square y)))
(sum-of-squares 3 4)
@i{25}
@end lisp

@noindent
Теперь и @code{sum-of-squares} мы можем использовать как строительный
блок при дальнейшем определении процедур:

@lisp
(define (f a)
  (sum-of-squares (+ a 1) (* a 2)))
(f 5)
@i{136}
@end lisp

@noindent
Составные процедуры используются точно так же, как элементарные. В
самом деле, глядя на приведенное выше определение @code{sum-of-squares},
невозможно выяснить, была ли @code{square} встроена в интерпретатор,
подобно @code{+} и @code{*}, или ее определили как составную процедуру.

@comment @subsection The Substitution Model for Procedure Application
@subsection Подстановочная модель применения процедуры
@node	1.1.5, 1.1.6, 1.1.4, 1.1

Вычисляя комбинацию, оператор которой называет составную процедуру,
интерпретатор осуществляет, вообще говоря, тот же процесс, что и для
комбинаций, операторы которых называют элементарные процедуры ---
процесс, описанный в разделе @ref{1.1.3}. А
именно, интерпретатор вычисляет элементы комбинации и применяет
процедуру (значение оператора комбинации) к аргументам (значениям
операндов комбинации).

Мы можем предположить, что механизм применения элементарных процедур к
аргументам встроен в интерпретатор. Для составных процедур процесс
протекает так:

@quotation
Чтобы применить составную процедуру к аргументам, требуется вычислить
тело процедуры, заменив каждый формальный параметр соответствующим
аргументом.
@end quotation

@noindent
Чтобы проиллюстрировать этот процесс, вычислим комбинацию

@lisp
(f 5)
@end lisp

@noindent
где @code{f} --- процедура, определенная в
разделе @ref{1.1.4}. Начинаем мы с того, что восстанавливаем тело @code{f}:

@lisp
(sum-of-squares (+ a 1) (* a 2))
@end lisp

@noindent
Затем мы заменяем формальный параметр @code{a} на аргумент 5:

@lisp
(sum-of-squares (+ 5 1) (* 5 2))
@end lisp

@noindent
Таким образом, задача сводится к вычислению комбинации с двумя
операндами и оператором @code{sum-of-squares}. Вычисление этой
комбинации включает три подзадачи. Нам нужно вычислить оператор, чтобы
получить процедуру, которую требуется применить, а также операнды,
чтобы получить аргументы. При этом @code{(+ 5 1)} дает 6, а
@code{(* 5 2)} дает 10, так что нам требуется применить процедуру
@code{sum-of-squares} к 6 и 10. Эти значения подставляются на место
формальных параметров @code{x} и @code{y} в теле @code{sum-of-squares},
приводя выражение к

@lisp
(+ (square 6) (square 10))
@end lisp

@noindent
Когда мы используем определение @code{square}, это приводится к

@lisp
(+ (* 6 6) (* 10 10))
@end lisp

@noindent
что при умножении сводится к

@lisp
(+ 36 100)
@end lisp

@noindent
и, наконец, к

@lisp
136
@end lisp

@noindent
Только что описанный нами процесс называется подстановочной
моделью (@newterm{substitution model}) применения процедуры. Ее можно
использовать как модель, которая определяет <<смысл>> понятия применения
процедуры, пока рассматриваются процедуры из этой главы. Имеются,
однако, две детали, которые необходимо подчеркнуть:

@itemize @bullet

@item
Цель подстановочной модели --- помочь нам представить, как применяются
процедуры, а не дать описание того, как на самом деле работает
интерпретатор. Как правило, интерпретаторы вычисляют применения
процедур к аргументам без манипуляций с текстом процедуры, которые
выражаются в подстановке значений для формальных параметров. На
практике <<подстановка>> реализуется с помощью локальных окружений для
формальных параметров. Более подробно мы обсудим это в
@ref{Глава 3} и @ref{Глава 4}, где мы детально исследуем реализацию
интерпретатора.

@item
На протяжении этой книги мы представим последовательность усложняющихся
моделей того, как работает интерпретатор, завершающуюся полным
воплощением интерпретатора и компилятора в @ref{Глава 5}.
Подстановочная модель --- только первая из них, способ начать формально
мыслить о моделях вычисления. Вообще, моделируя различные явления в
науке и технике, мы начинаем с упрощенных, неполных моделей.
Подстановочная модель в этом смысле не исключение. В частности,
когда в @ref{Глава 3}
мы обратимся к использованию процедур с <<изменяемыми данными>>, то мы
увидим, что подстановочная модель этого не выдерживает и ее нужно
заменить более сложной моделью применения процедур.@footnote{Несмотря на
простоту подстановочной модели, дать строгое математическое определение
процессу подстановки оказывается удивительно сложно. Проблема возникает
из-за возможности смешения имен, которые используются как формальные
параметры процедуры, с именами (возможно, с ними совпадающими), которые
используются в выражениях, к которым процедура может применяться.
Имеется долгая история неверных определений подстановки
(@newterm{substitution}) в литературе по логике и языкам программирования.
Подробное обсуждение подстановки можно найти в @ref{Stoy 1977}.}

@end itemize

@comment @subsubheading Applicative order versus normal order
@subsubheading Аппликативный и нормальный порядки вычисления

В соответствии с описанием из раздела @ref{1.1.3}, интерпретатор сначала
вычисляет оператор и операнды, а затем применяет получившуюся
процедуру к получившимся аргументам. Но это не единственный способ
осуществлять вычисления. Другая модель вычисления не вычисляет
аргументы, пока не понадобится их значение. Вместо этого она подставляет
на место параметров выражения-операнды, пока не получит выражение, в
котором присутствуют только элементарные операторы, и лишь затем
вычисляет его. Если бы мы использовали этот метод, вычисление
@code{(f 5)} прошло бы последовательность подстановок

@lisp
(sum-of-squares (+ 5 1) (* 5 2))
(+   (square (+ 5 1))      (square (* 5 2))  )
(+   (* (+ 5 1) (+ 5 1))   (* (* 5 2) (* 5 2)))
@end lisp

@noindent
за которыми последуют редукции

@lisp
(+      (* 6 6)      (* 10 10))
(+         36           100)
                136
@end lisp

@noindent
Это дает тот же результат, что и предыдущая модель вычислений, но
процесс его получения отличается. В частности, вычисление
@code{(+ 5 1)} и @code{(* 5 2)} выполняется здесь по два раза, в
соответствии с редукцией выражения @code{(* x x)} где @code{x} заменяется,
соответственно, на @code{(+ 5 1)} и @code{(* 5 2)}.

Альтернативный метод <<полная подстановка, затем редукция>> известен под
названием (@newterm{normal-order evaluation}), в противоположность методу
<<вычисление аргументов, затем применение процедуры>>, которое
называется (@newterm{applicative-order evaluation}). Можно показать, что для
процедур, которые правильно моделируются с помощью подстановки (включая
все процедуры из первых двух глав этой книги) и возвращают законные
значения, нормальный и аппликативный порядки вычисления дают одно и то
же значение. (См. упражнение @ref{Упражнение 1.5}, где приводится
пример <<незаконного>> выражения, для которого нормальный и
аппликативный порядки вычисления дают разные результаты.)

В Лиспе используется аппликативный порядок вычислений, отчасти из-за
дополнительной эффективности, которую дает возможность не вычислять
многократно выражения вроде приведенных выше @code{(+ 5 1)} и
@code{(* 5 2)}, а отчасти, что важнее, потому что с нормальным порядком
вычислений становится очень сложно обращаться, как только мы покидаем
область процедур, которые можно смоделировать с помощью подстановки. С
другой стороны, нормальный порядок вычислений может быть весьма ценным
инструментом, и некоторые его применения мы рассмотрим в @ref{Глава 3} и
@ref{Глава 4}.@footnote{В @ref{Глава 3}
мы описываем (@newterm{stream processing}), которая представляет собой способ
обработки структур данных, кажущихся <<бесконечными>>, с помощью
ограниченной формы нормального порядка вычислений. В разделе @ref{4.2}
мы модифицируем интерпретатор Scheme так, что получается вариант языка с
нормальным порядком вычислений.}

@comment @subsection Conditional Expressions and Predicates
@subsection Условные выражения и предикаты
@node	1.1.6, 1.1.7, 1.1.5, 1.1

Выразительная сила того класса процедур, которые мы уже научились
определять, очень ограничена, поскольку пока что у нас нет способа
производить проверки и выполнять различные операции в зависимости от
результата проверки. Например, мы не способны определить процедуру,
вычисляющую модуль числа, проверяя, положительное ли это число,
отрицательное или ноль, и предпринимая различные действия в
соответствии с правилом
@ifinfo

@example
      /
      |   x  if x > 0
|x| = <   0  if x = 0
      |  -x  if x < 0
      \
@end example

@end ifinfo
@tex
$$
 |x| = \left\{ \begin{array}{r@{\quad \mathrm{if} \quad}l}
        x  &  x > 0, \\
	0  &  x = 0, \\
  \!\! -x  &  x < 0. \end{array} \right.
$$
@end tex
Такая конструкция называется (@newterm{case analysis}). В Лиспе существует особая
форма для обозначения такого разбора случаев. Она называется @code{cond}
(от английского слова conditional, <<условный>>) и используется
так:

@lisp
(define (abs x)
  (cond ((> x 0) x)
        ((= x 0) 0)
        ((< x 0) (- x))))
@end lisp

@noindent
Общая форма условного выражения такова:

@lisp
(cond (@math{\langle}@var{p}@math{_{\mono{1}}\rangle} @math{\langle}@var{e}@math{_{\mono{1}}\rangle})
      (@math{\langle}@var{p}@math{_{\mono{2}}\rangle} @math{\langle}@var{e}@math{_{\mono{2}}\rangle})
      @dots{}
      (@math{\langle}@var{p}@math{_{\monoit{n}}\rangle} @math{\langle}@var{e}@math{_{\monoit{n}}\rangle}))
@end lisp

@noindent
Она состоит из символа @code{cond}, за которым следуют заключенные в
скобки пары выражений

@lisp
(@math{\langle}@var{p}@math{\rangle} @math{\langle}@var{e}@math{\rangle})
@end lisp

@noindent
называемых (@newterm{clauses}). В каждой из этих пар первое выражение ---
(@newterm{predicate}), то есть выражение, значение которого интерпретируется как
истина или ложь.@footnote{<<Интерпретируется как истина или ложь>>
означает следующее: в языке Scheme есть два выделенных значения,
которые обозначаются константами @code{\#t} и @code{\#f}. Когда
интерпретатор проверяет значение предиката, он интерпретирует @code{\#f}
как ложь. Любое другое значение считается истиной. (Таким образом,
наличие @code{\#t} логически не является необходимым, но иметь его
удобно.) В этой книге мы будем использовать имена @code{true} и
@code{false}, которые связаны со значениями @code{\#t} и @code{\#f},
соответственно.}

Условные выражения вычисляются так: сначала вычисляется предикат
@math{\langle{p_1}\rangle}. Если его значением является ложь, вычисляется
@math{\langle{p_2}\rangle}. Если значение @math{\langle{p_2}\rangle} также ложь,
вычисляется @math{\langle{p_3}\rangle}.
Этот процесс продолжается до тех пор, пока не найдется предикат,
значением которого будет истина, и в этом случае интерпретатор
возвращает значение соответствующего (@newterm{consequent expression})
в качестве значения всего условного выражения. Если ни один из
@math{\langle{p}\rangle} ни окажется истинным, значение
условного выражения @code{cond} не определено.

Словом (@newterm{predicate}) называют процедуры, которые возвращают истину или ложь, а также
выражения, которые имеют значением истину или ложь. Процедура вычисления
модуля @code{abs} использует элементарные предикаты @code{<}, @code{>}
и @code{=}.@footnote{Еще она использует операцию <<минус>> @code{-}, 
которая, когда используется с одним операндом, как в выражении @code{(- x)},
обозначает смену знака.}

Они принимают в качестве аргументов по два числа и, проверив, меньше ли
первое из них второго, равно ему или больше, возвращают в зависимости
от этого истину или ложь.

Можно написать процедуру вычисления модуля и так:

@lisp
(define (abs x)
  (cond ((< x 0) (- x))
        (else x)))
@end lisp

@noindent
что на русском языке можно было бы выразить следующим образом: <<если
@math{x} меньше нуля, вернуть @math{-x}; иначе вернуть @math{x}>>.
@code{else} --- специальный символ, который в заключительной ветви
@code{cond} можно использовать на месте @math{\langle{p}\rangle}. Это
заставляет @code{cond} вернуть в качестве значения значение соответствующего
@math{\langle{e}\rangle} в случае, если все предыдущие
ветви были пропущены. На самом деле, здесь на месте
@math{\langle{p}\rangle} можно было бы использовать любое
выражение, которое всегда имеет значение истина.

Вот еще один способ написать процедуру вычисления модуля:

@lisp
(define (abs x)
  (if (< x 0)
      (- x)
      x))
@end lisp

@noindent
Здесь употребляется особая форма @code{if}, ограниченный вид условного
выражения. Его можно использовать при разборе случаев, когда есть ровно
два возможных исхода. Общая форма выражения @code{if} такова:

@lisp
(if @math{\langle\kern0.07em}@var{предикат}@math{\kern0.06em\rangle} @math{\langle\kern0.07em}@var{следствие}@math{\kern0.05em\rangle} @math{\langle\kern0.06em}@var{альтернатива}@math{\kern0.06em\rangle})
@end lisp

@noindent
Для того чтобы вычислить выражение @code{if}, интерпретатор сначала вычисляет
его @math{\langle}@var{предикат}@math{\kern0.04em\rangle}. Если
@math{\langle}@var{предикат}@math{\kern0.04em\rangle} дает истинное значение,
интерпретатор вычисляет @math{\langle}@var{следствие}@math{\kern0.04em\rangle} и возвращает его значение. В противном случае он вычисляет
@math{\langle}@var{альтернативу}@math{\kern0.04em\rangle} и возвращает ее
значение.@footnote{Небольшая разница между @code{if} и @code{cond}
состоит в том, что в @code{cond} каждое @math{\langle{e}\rangle}
может быть последовательностью выражений. Если соответствующее
@math{\langle{p}\rangle} оказывается истинным, выражения из
@math{\langle{e}\rangle} вычисляются по очереди, и в качестве значения
@code{cond} возвращается значение последнего из них. Напротив, в @code{if} как
@math{\langle}@var{следствие}@math{\kern0.04em\rangle}, так и
@math{\langle}@var{альтернатива}@math{\kern0.04em\rangle}
обязаны состоять из одного выражения.}

В дополнение к элементарным предикатам вроде @code{<}, @code{=} и
@code{>}, существуют операции логической композиции, которые позволяют
нам конструировать составные предикаты. Из них чаще всего используются
такие:

@itemize @bullet

@item
@math{\hbox{\tt(and }\langle{e_1}\rangle\;\;\dots\;\;\langle{e_n}\rangle\hbox{\tt)}}

Интерпретатор вычисляет выражения @math{\langle{e}\kern0.08em\rangle}
по одному, слева направо. Если какое-нибудь из
@math{\langle{e}\kern0.08em\rangle} дает ложное значение, значение всего
выражения @code{and} --- ложь, и остальные @math{\langle{e}\kern0.08em\rangle}
не вычисляются. Если все @math{\langle{e}\kern0.08em\rangle}
дают истинные значения, значением выражения @code{and} является истина.

@item
@math{\hbox{\tt(or }\langle{e_1}\rangle\;\;\dots\;\;\langle{e_n}\rangle\hbox{\tt)}}

Интерпретатор вычисляет выражения
@math{\langle{e}\kern0.08em\rangle} 
по одному, слева направо. Если какое-нибудь из
@math{\langle{e}\kern0.08em\rangle}
дает истинное значение, это значение возвращается как результат выражения
@code{or}, а остальные
@math{\langle{e}\kern0.08em\rangle}
не вычисляются. Если все
@math{\langle{e}\kern0.08em\rangle}
оказываются ложными, значением выражения @code{or} является ложь.

@item
@math{\hbox{\tt(not }\langle{e}\rangle\hbox{\tt)}}

Значение выражения @code{not} --- истина, если значение выражения
@math{\langle{e}\kern0.08em\rangle} ложно, и ложь в противном случае.

@end itemize

@noindent
Заметим, что @code{and} и @code{or} --- особые формы, а не процедуры,
поскольку не обязательно вычисляются все подвыражения. @code{Not} ---
обычная процедура.

Как пример на использование этих конструкций, условие что число @math{x}
находится в диапазоне @math{5 < x < 10}, можно выразить как

@lisp
(and (> x 5) (< x 10))
@end lisp

@noindent
Другой пример: мы можем определить предикат, который проверяет, что одно
число больше или равно другому, как

@lisp
(define (>= x y) (or (> x y) (= x y)))
@end lisp

@noindent
или как

@lisp
(define (>= x y) (not (< x y)))
@end lisp

@quotation
@strong{@anchor{Упражнение 1.1}Упражнение 1.1:} Ниже приведена
последовательность выражений. Какой результат
напечатает интерпретатор в ответ на каждое из них? Предполагается, что
выражения вводятся в том же порядке, в каком они написаны.

@lisp
10
(+ 5 3 4)
(- 9 1)
(/ 6 2)
(+ (* 2 4) (- 4 6))
(define a 3)
(define b (+ a 1))
(+ a b (* a b))
(= a b)
(if (and (> b a) (< b (* a b)))
    b
    a)
@end lisp

@lisp
(cond ((= a 4) 6)
      ((= b 4) (+ 6 7 a))
      (else 25))
@end lisp

@lisp
(+ 2 (if (> b a) b a))
@end lisp

@lisp
(* (cond ((> a b) a)
         ((< a b) b)
         (else -1))
   (+ a 1))
@end lisp
@end quotation

@quotation
@strong{@anchor{Упражнение 1.2}Упражнение 1.2:} 
Переведите следующее выражение в префиксную форму:
@ifinfo

@example
5 + 4 + (2 - (3 - (6 + 4/5)))
-----------------------------
       3(6 - 2)(2 - 7)
@end example

@end ifinfo
@tex
$${5 + 4 + (2 - (3 - (6 + {4\over5})))\over3(6 - 2)(2 - 7)}.$$
@end tex
@end quotation

@quotation
@strong{@anchor{Упражнение 1.3}Упражнение 1.3:} 
Определите процедуру, которая принимает в качестве
аргументов три числа и возвращает сумму квадратов двух бо́льших из них.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.4}Упражнение 1.4:} Заметим, что наша модель
вычислений разрешает существование комбинаций, операторы которых --- составные
выражения. С помощью этого наблюдения опишите, как работает следующая процедура:

@lisp
(define (a-plus-abs-b a b)
  ((if (> b 0) + -) a b))
@end lisp
@end quotation

@quotation
@strong{@anchor{Упражнение 1.5}Упражнение 1.5:}
Бен Битобор придумал тест для проверки интерпретатора на то, с каким
порядком вычислений он работает, аппликативным или нормальным.
Бен определяет такие две процедуры:

@lisp
(define (p) (p))
(define (test x y)
  (if (= x 0) 0 y
@end lisp

Затем он вычисляет выражение

@lisp
(test 0 (p))
@end lisp

Какое поведение увидит Бен, если интерпретатор использует аппликативный
порядок вычислений? Какое поведение он увидит, если интерпретатор
использует нормальный порядок? Объясните Ваш ответ. (Предполагается, что
правило вычисления особой формы @code{if} одинаково независимо от того,
какой порядок вычислений используется. Сначала вычисляется
выражение-предикат, и результат определяет, нужно ли вычислять
выражение-следствие или альтернативу.)

@end quotation

@endpage
@comment @subsection Example: Square Roots by Newton's Method
@subsection Пример: вычисление квадратного корня методом Ньютона
@node	1.1.7, 1.1.8, 1.1.6, 1.1

Процедуры, как они описаны выше, очень похожи на обыкновенные
математические функции. Они устанавливают значение, которое определяется
одним или более параметром. Но есть важное различие между
математическими функциями и компьютерными процедурами. Процедуры должны
быть эффективными.

В качестве примера рассмотрим задачу вычисления квадратного корня. Мы
можем определить функцию <<квадратный корень>> так:
@ifinfo

@example
sqrt(x) = такое y, что y >= 0 и y^2 = x
@end example

@end ifinfo
@tex
$$\sqrt{x} =  такое y, что y \ge 0 и y^2 = x$$
@end tex

@comment $$\sqrt{x}\;\; = {\rm\;\; такое\;\;} y
@comment {\rm\;\; что\;\;} y \ge 0 {\rm\;\; и\;\;} y^2 = x.$$

Это описывает совершенно нормальную математическую функцию. С помощью
такого определения мы можем решать, является ли одно число квадратным
корнем другого, или выводить общие свойства квадратных корней. С другой
стороны, это определение не описывает процедуры. В самом деле, оно почти
ничего не говорит о том, как найти квадратный корень данного числа. Не
поможет и попытка перевести это определение на псевдо-Лисп:

@lisp
(define (sqrt x)
  (the y (and (>= y 0)
              (= (square y) x))))
@end lisp

@noindent
Это только уход от вопроса.

Противопоставление функций и процедур отражает общее различие между
описанием свойств объектов и описанием того, как что-то делать, или,
как иногда говорят, различие между декларативным знанием и императивным
знанием. В математике нас обычно интересуют декларативные описания (что
такое), а в информатике императивные описания
(как).@footnote{Декларативные и императивные описания тесно связаны
между собой, как и математика с информатикой. Например, сказать, что
ответ, получаемый программой, <<верен>>, означает сделать об этой
программе декларативное утверждение. Существует большое количество
исследований, направленных на отыскание методов доказательства того, что
программа корректна, и большая часть сложности этого предмета
исследования связана с переходом от императивных утверждений (из
которых строятся программы) к декларативным (которые можно использовать
для рассуждений). Связана с этим и такая важная область современных
исследований по проектированию языков программирования, как исследование
так называемыхязыков сверхвысокого уровня, в которых программирование
на самом деле происходит в терминах декларативных утверждений. Идея
состоит в том, чтобы сделать интерпретаторы настолько умными, чтобы,
получая от программиста знание типа <<что такое>>, они были бы способны
самостоятельно породить знание типа <<как>>. В общем случае это сделать
невозможно, но есть важные области, где удалось достичь прогресса. Мы
вернемся к этой идее в @ref{Глава 4}.}

Как вычисляются квадратные корни? Наиболее часто применяется Ньютонов
метод последовательных приближений, который основан на том, что имея
некоторое неточное значение @math{y} для квадратного корня из числа
@math{x}, мы можем с помощью простой манипуляции получить более точное
значение (более близкое к настоящему квадратному корню), если возьмем
среднее между @math{y} и @math{x/y}.@footnote{На самом деле алгоритм
нахождения квадратного корня представляет собой частный случай метода
Ньютона, который является общим методом нахождения корней уравнений.
Собственно алгоритм нахождения квадратного корня был разработан Героном
Александрийским в первом веке @acronym{н.э.} Мы увидим, как выразить общий метод
Ньютона в виде процедуры на Лиспе, в разделе @ref{1.3.4}.} Например, мы
можем вычислить квадратный корень из 2 следующим образом: предположим,
что начальное приближение равно 1.

@sp -0.8
@smallexample
Приближение Частное                  Среднее
1           (2/1) = 2                ((2 + 1)/2) = 1.5
1.5         (2/1.5) = 1.3333         ((1.3333 + 1.5)/2) = 1.4167
1.4167      (2/1.4167) = 1.4118      ((1.4167 + 1.4118)/2) = 1.4142
1.4142      ...                      ...
@end smallexample

@noindent
Продолжая этот процесс, мы получаем все более точные
приближения к квадратному корню.

Теперь формализуем этот процесс в терминах процедур. Начнем с
подкоренного числа и какого-то значения приближения. Если приближение
достаточно хорошо подходит для наших целей, то процесс закончен; если
нет, мы должны повторить его с улучшенным значением приближения.
Запишем эту базовую стратегию в виде процедуры:

@lisp
(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x) x)))
@end lisp

@noindent
Значение приближения улучшается с помощью взятия среднего между ним и
частным подкоренного числа и старого значения приближения:

@lisp
(define (improve guess x)
  (average guess (/ x guess)))
@end lisp

@noindent
где

@lisp
(define (average x y)
  (/ (+ x y) 2))
@end lisp

@noindent
Нам нужно еще сказать, что такое для нас <<достаточно хорошее>>
приближение. Следующий вариант сойдет для иллюстрации, но на самом деле
это не очень хороший тест. (См. @ref{Упражнение 1.7}.) Идея
состоит в том, чтобы улучшать приближения до тех пор, пока его квадрат
не совпадет с подкоренным числом в пределах заранее заданного допуска
(здесь 0.001):@footnote{Обычно мы будем давать предикатам имена,
заканчивающиеся знаком вопроса, чтобы было проще запомнить, что это
предикаты. Это не более чем стилистическое соглашение. С точки зрения
интерпретатора, вопросительный знак --- обыкновенный символ.}

@lisp
(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.001))
@end lisp

@noindent
Наконец, нужно с чего-то начинать. Например, мы можем для начала
предполагать, что квадратный корень любого числа равен
1.@footnote{Обратите внимание, что мы записываем начальное приближение
как 1.0, а не как 1.Во многих реализациях Лиспа здесь не будет никакой
разницы. Однако интерпретатор @acronym{MIT} Scheme отличает точные целые числа от
десятичных значений, и при делении двух целых получается не десятичная
дробь, а рациональное число. Например, поделив 10/6, получим 5/3, а
поделив 10.0/6.0, получим 1.6666666666666667. (Мы увидим, как
реализовать арифметические операции над рациональными числами, в
разделе @ref{2.1.1}.)
Если в нашей программе квадратного корня мы начнем с начального
приближения 1, а @math{x} будет точным целым числом, все последующие
значения, получаемые при вычислении квадратного корня, будут не
десятичными дробями, а рациональными числами. Поскольку при смешанных
операциях над десятичными дробями и рациональными числами всегда
получаются десятичные дроби, то начав со значения 1.0, все прочие мы
получим в виде десятичных дробей.}

@lisp
(define (sqrt x)
  (sqrt-iter 1.0 x))
@end lisp

@noindent
Если мы введем эти определения в интерпретатор, мы сможем использовать
@code{sqrt} как любую другую процедуру:

@lisp
(sqrt 9)
@i{3.00009155413138}

(sqrt (+ 100 37))
@i{11.704699917758145}

(sqrt (+ (sqrt 2) (sqrt 3)))
@i{1.7739279023207892}

(square (sqrt 1000))
@i{1000.000369924366}
@end lisp

@noindent
Программа @code{sqrt} показывает также, что того простого процедурного
языка, который мы описали до сих пор, достаточно, чтобы написать любую
чисто вычислительную программу, которую можно было бы написать, скажем,
на Си или Паскале. Это может показаться удивительным, поскольку в наш
язык мы не включили никаких итеративных (циклических) конструкций,
указывающих компьютеру, что нужно производить некое действие несколько
раз. @code{sqrt-iter}, с другой стороны, показывает, как можно выразить
итерацию, не имея никакого специального конструкта, кроме обыкновенной
способности вызвать процедуру.@footnote{Читателям, которых заботят
вопросы эффективности, связанные с использованием вызовов процедур для
итерации, следует обратить внимание на замечания о <<хвостовой
рекурсии>> в разделе @ref{1.2.1}.}

@quotation
@strong{@anchor{Упражнение 1.6}Упражнение 1.6:}
Лиза П. Хакер не понимает, почему @code{if} должна быть
особой формой. <<Почему нельзя просто определить ее как обычную
процедуру с помощью @code{cond}?>> --- спрашивает она. Лизина подруга
Ева Лу Атор утверждает, что, разумеется, можно, и определяет новую
версию @code{if}:

@lisp
(define (new-if predicate then-clause else-clause)
  (cond (predicate then-clause)
        (else else-clause)))
@end lisp

Ева показывает Лизе новую программу:

@lisp
(new-if (= 2 3) 0 5)
@i{5}
(new-if (= 1 1) 0 5)
@i{0}
@end lisp

Обрадованная Лиза переписывает через @code{new-if} программу вычисления
квадратного корня:

@lisp
(define (sqrt-iter guess x)
  (new-if (good-enough? guess x)
          guess
          (sqrt-iter (improve guess x) x)))
@end lisp

Что получится, когда Лиза попытается использовать эту процедуру для
вычисления квадратных корней? Объясните.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.7}Упражнение 1.7:}
Проверка @code{good-enough?}, которую мы использовали для
вычисления квадратных корней, будет довольно неэффективна для поиска
квадратных корней от очень маленьких чисел. Кроме того, в настоящих
компьютерах арифметические операции почти всегда вычисляются с
ограниченной точностью. Поэтому наш тест оказывается неадекватным и для
очень больших чисел. Альтернативный подход к реализации
@code{good-enough?} состоит в том, чтобы следить, как от одной
итерации к другой изменяется @code{guess}, и остановиться, когда
изменение оказывается небольшой долей значения приближения. Разработайте
процедуру вычисления квадратного корня, которая использует такой вариант
проверки на завершение. Верно ли, что на больших и маленьких числах она
работает лучше?
@end quotation

@quotation
@strong{@anchor{Упражнение 1.8}Упражнение 1.8:}
Метод Ньютона для кубических корней основан на том, что если
@math{y} является приближением к кубическому корню из @math{x}, то мы
можем получить лучшее приближение по формуле
@ifinfo

@example
x/y^2 + 2y
----------
    3
@end example

@end ifinfo
@tex
$${{x / y^2} + 2y \over 3}.$$
@end tex
@noindent
С помощью этой формулы напишите процедуру
вычисления кубического корня, подобную процедуре для квадратного корня.
(В разделе @ref{1.3.4} мы увидим, что
можно реализовать общий метод Ньютона как абстракцию этих процедур для
квадратного и кубического корня.)
@end quotation

@comment @subsection Procedures as Black-Box Abstractions
@subsection Процедуры как абстракции типа <<черный ящик>>
@node	1.1.8,  , 1.1.7, 1.1

@code{sqrt} --- наш первый пример процесса, определенного множеством
зависимых друг от друга процедур. Заметим, что определение
@code{sqrt-iter} (@newterm{recursive}); это означает, что процедура
определяется в терминах самой себя. Идея, что можно определить
процедуру саму через себя, возможно, кажется Вам подозрительной; неясно,
как такое <<циклическое>> определение вообще может иметь смысл, не то
что описывать хорошо определенный процесс для исполнения компьютером.
Более осторожно мы подойдем к этому в
разделе @ref{1.2}.
Рассмотрим, однако, некоторые другие важные детали, которые иллюстрирует
пример с @code{sqrt}.

Заметим, что задача вычисления квадратных корней естественным образом
разбивается на подзадачи: как понять, что очередное приближение нас
устраивает, как улучшить очередное приближение, и так далее. Каждая из
этих задач решается с помощью отдельной процедуры. Вся программа
@code{sqrt} может рассматриваться как пучок процедур (показанный на
рис. @ref{Рисунок 1.2}), отражающий декомпозицию задачи на подзадачи.

@float
@quotation
@anchor{Рисунок 1.2}
@ifinfo
@strong{Рисунок 1.2:} Процедурная декомπозиция πрограммы @code{sqrt}.

@example
                       sqrt
                        |
                    sqrt-iter
                    /       \
            good-enough    improve
              /     \          \
          square    abs      average
@end example
@end ifinfo
@iftex
@sp 0.5
@center @image{fig/chap1/Fig1.2,44mm,,,.pdf}
@sp 0.5
@center @caption{@strong{Рисунок 1.2:} Процедурная декомπозиция πрограммы @code{sqrt}.}
@sp 0.7
@end iftex
@end quotation
@end float

Важность декомпозиционной стратегии не просто в том, что задача
разделяется на части. В конце концов, можно взять любую большую
программу и поделить ее на части: первые десять строк, следующие десять
строк и так далее. Существенно то, что каждая процедура выполняет точно
определенную задачу, которая может быть использована при определении
других процедур. Например, когда мы определяем процедуру
@code{good-enough?} с помощью @code{square}, мы можем рассматривать
процедуру @code{square} как <<черный ящик>>. В этот момент нас не
интересует, @emph{как} она вычисляет свой результат, --- важно только
то, что она способна вычислить квадрат. О деталях того, как вычисляют
квадраты, можно сейчас забыть и рассмотреть их потом. Действительно,
пока мы рассматриваем процедуру @code{good-enough?}, @code{square} ---
не совсем процедура, но скорее абстракция процедуры, так называемая
(@newterm{procedural abstraction}). На этом уровне абстракции все процедуры,
вычисляющие квадрат, одинаково хороши.

Таким образом, если рассматривать только возвращаемые значения, то
следующие две процедуры для возведения числа в квадрат будут неотличимы
друг от друга. Каждая из них принимает числовой аргумент и возвращает в
качестве значения квадрат этого числа.@footnote{Неясно даже, которая из
этих процедур более эффективна. Это зависит от того, какая имеется
аппаратура. Существуют машины, на которых <<очевидная>> реализация будет
медленней. Представьте себе машину, в которой очень эффективным
способом хранятся большие таблицы логарифмов и обратных логарифмов.}

@lisp
(define (square x) (* x x))
(define (square x) (exp (double (log x))))
(define (double x) (+ x x))
@end lisp

@noindent
Таким образом, определение процедуры должно быть способно скрывать
детали. Может оказаться, что пользователь процедуры не сам ее
написал, а получил от другого программиста как черный ящик. От
пользователя не должно требоваться знания, как работает процедура, чтобы
ее использовать.

@comment @subsubheading Local name
@subsubheading Локальные имена

Одна из деталей реализации, которая не должна заботить пользователя
процедуры --- это то, какие человек, писавший процедуру, выбрал имена
для формальных параметров процедуры. Таким образом, следующие две
процедуры должны быть неотличимы:

@lisp
(define (square x) (* x x))
(define (square y) (* y y))
@end lisp

@noindent
Этот принцип --- что значение процедуры не должно зависеть от имен
параметров, которые выбрал ее автор, --- может сначала показаться
очевидным, однако он имеет глубокие следствия. Простейшее из этих
следствий состоит в том, что имена параметров должны быть локальными в
теле процедуры. Например, в программе вычисления квадратного корня при
определении @code{good-enough?} мы использовали @code{square}:

@lisp
(define (good-enough? guess x)
  (< (abs (- (square guess) x))
     0.001))
@end lisp

@noindent
Намерение автора @code{good-enough?} состоит в том, чтобы определить,
достаточно ли близко квадрат первого аргумента лежит ко второму. Мы
видим, что автор @code{good-enough?} обращается к первому аргументу с
помощью имени @code{guess}, а ко второму с помощью имени @code{x}.
Аргументом @code{square} является @code{guess}. Поскольку автор
@code{square} использовал имя @code{x} (как мы видели выше), чтобы
обратиться к этому аргументу, мы видим, что @code{x} в
@code{good-enough?} должно отличаться от @code{x} в @code{square}.
Запуск процедуры @code{square} не должен отразиться на значении
@code{x}, которое использует @code{good-enough?}, поскольку это значение
@code{x} понадобится @code{good-enough?}, когда @code{square} будет
вычислена.

Если бы параметры не были локальны по отношению к телам своих процедур,
то параметр @code{x} в @code{square} смешался бы с параметром @code{x}
из @code{good-enough?}, и поведение @code{good-enough?} зависело бы от
того, какую версию @code{square} мы использовали. Таким образом,
процедура @code{square} не была бы черным ящиком, как мы того хотим.

У формального параметра особая роль в определении процедуры: не имеет
значения, какое у этого параметра имя. Такое имя называется (@newterm{bound variable}),
и мы будем говорить, что определение процедуры (@newterm{binds}) свои
формальные параметры. Значение процедуры не изменяется, если во всем ее
определении параметры последовательным образом
переименованы.@footnote{Понятие последовательного переименования на самом
деле достаточно тонкое и трудное для определения. Знаменитым логикам
случалось делать здесь ужасные ошибки.} Если переменная не связана, мы
говорим, что она (@newterm{free}). Множество выражений, для которых связывание
определяет имя, называется (@newterm{scope}) этого имени. В определении процедуры
связанные переменные, объявленные как формальные параметры процедуры,
имеют своей областью действия тело процедуры.

В приведенном выше определении @code{good-enough?}, @code{guess} и
@code{x} --- связанные переменные, а @code{<}, @code{-}, @code{abs} и
@code{square} --- свободные. Значение @code{good-enough?} должно быть
независимо от того, какие имена мы выберем для @code{guess} и @code{x},
пока они остаются отличными друг от друга и от @code{<}, @code{-},
@code{abs} и @code{square}. (Если бы мы переименовали @code{guess} в
@code{abs}, то породили бы ошибку, (@newterm{capture}) переменную @code{abs}.
Она превратилась бы из свободной в связанную.) Однако значение
@code{good-enough?} не является независимым от ее свободных переменных.
Разумеется, оно зависит от того факта (внешнего по отношению к этому
определению), что символ @code{abs} называет процедуру вычисления модуля
числа. @code{good-enough?} будет вычислять совершенно другую функцию,
если в ее определении мы вместо @code{abs} подставим @code{cos}.

@comment @subsubheading Internal definitions and block structure
@subsubheading Внутренние определения и блочная структура

До сих пор нам был доступен только один вид изоляции имен: формальные
параметры процедуры локальны по отношению к телу этой процедуры.
Программа вычисления квадратного корня иллюстрирует еще один вид
управления использованием имен, которым мы хотели бы владеть.
Существующая программа состоит из отдельных процедур:

@lisp
(define (sqrt x)
  (sqrt-iter 1.0 x))
(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x) x)))
(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.001))
(define (improve guess x)
  (average guess (/ x guess)))
@end lisp

@noindent
Проблема здесь состоит в том, что единственная процедура, которая важна
для пользователей @code{sqrt} --- это сама @code{sqrt}. Остальные
процедуры (@code{sqrt-iter}, @code{good-enough?} и @code{improve})
только забивают им головы. Теперь пользователи не могут определять
других процедур с именем @code{good-enough?} ни в какой другой
программе, которая должна работать совместно с программой вычисления
квадратного корня, поскольку @code{sqrt} требуется это имя. Эта проблема
становится особенно тяжелой при построении больших систем, которые пишут
много различных программистов. Например, при построении большой
библиотеки численных процедур многие числовые функции вычисляются как
последовательные приближения и могут потому иметь в качестве
вспомогательных процедуры @code{good-enough?} и @code{improve}. Нам
хотелось бы локализовать подпроцедуры, спрятав их внутри @code{sqrt},
так, чтобы @code{sqrt} могла сосуществовать с другими последовательными
приближениями, при том что у каждой из них была бы своя собственная
процедура @code{good-enough?}. Чтобы сделать это возможным, мы разрешаем
процедуре иметь внутренние определения, локальные для этой процедуры.
Например, при решении задачи вычисления квадратного корня мы можем
написать

@lisp
(define (sqrt x)
  (define (good-enough? guess x)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess x) (average guess (/ x guess)))
  (define (sqrt-iter guess x)
    (if (good-enough? guess x)
        guess
        (sqrt-iter (improve guess x) x)))
  (sqrt-iter 1.0 x))
@end lisp

@noindent
Такое вложение определений, называемое (@newterm{block structure}), дает
правильное решение для простейшей задачи упаковки имен. Но здесь таится
еще одна идея. Помимо того, что мы можем вложить определения
вспомогательных процедур внутрь главной, мы можем их упростить.
Поскольку переменная @code{x} связана в определении @code{sqrt},
процедуры @code{good-enough?}, @code{improve} и @code{sqrt-iter},
которые определены внутри @code{sqrt}, находятся в области действия
@code{x}. Таким образом, нет нужды явно передавать @code{x} в каждую из
этих процедур. Вместо этого мы можем сделать @code{x} свободной
переменной во внутренних определениях, как это показано ниже. Тогда
@code{x} получит свое значение от аргумента, с которым вызвана
объемлющая их процедура @code{sqrt}. Такой порядок называется
(@newterm{lexical scoping})
переменных.@footnote{Правило лексической сферы действия говорит,
что свободные переменные в процедуре ссылаются на связывания этих
переменных, сделанные в объемлющих определениях процедур; то есть они
ищутся в окружении, в котором процедура была определена. Мы детально
рассмотрим, как это работает, в @ref{Глава 3},
когда будем подробно описывать окружения и работу интерпретатора.}

@lisp
(define (sqrt x)
  (define (good-enough? guess)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess)
    (average guess (/ x guess)))
  (define (sqrt-iter guess)
    (if (good-enough? guess)
        guess
        (sqrt-iter (improve guess))))
  (sqrt-iter 1.0))
@end lisp

\enlargethispage{\baselineskip}

@noindent
Мы будем часто использовать блочную структуру, чтобы разбивать большие
программы на куски разумного размера.@footnote{Внутренние
определения должны быть в начале тела процедуры. За последствия запуска
программ, перемешивающих определения и их использование, администрация
ответственности не несет.} Идея блочной структуры происходит из языка
программирования Алгол 60. Она присутствует в большинстве современных
языков программирования. Это важный инструмент, который помогает
организовать построение больших программ.

@comment @section Procedures and the Processes They @w{Generate}
@section Процедуры и @w{Порождаемые} ими процессы
@node	1.2, 1.3, 1.1, Глава 1

В предыдущем разделе мы рассмотрели элементы программирования. Мы
использовали элементарные арифметические операции, комбинировали их и
абстрагировали получившиеся составные операции путем определения
составных процедур. Но всего этого еще недостаточно, чтобы сказать, что
мы умеем программировать. Положение, в котором мы находимся, похоже на
положение человека, выучившего шахматные правила, но ничего не знающего
об основных дебютах, тактике и стратегии. Подобно шахматисту-новичку, мы
пока ничего не знаем об основных схемах использования понятий в нашей
области знаний. Нам недостает знаний о том, какие именно ходы следует
делать (какие именно процедуры имеет смысл определять), и не хватает
опыта предсказания последствий сделанного хода (выполнения процедуры).

Способность предвидеть последствия рассматриваемых действий необходима
для того, чтобы стать квалифицированным программистом, --- равно как и
для любой другой синтетической, творческой деятельности. Например,
квалифицированному фотографу нужно при взгляде на сцену понимать,
насколько темным каждый ее участок покажется после печати при разном
выборе экспозиции и разных условиях обработки. Только после этого можно
проводить обратные рассуждения и выбирать кадр, освещение,
экспозицию и условия обработки так, чтобы получить желаемый результат.
Чтобы стать специалистами, нам надо научиться представлять процессы,
генерируемые различными типами процедур. Только развив в себе такую
способность, мы сможем научиться надежно строить программы, которые
ведут себя так, как нам надо.

Процедура представляет собой шаблон (@newterm{local evolution}) вычислительного
процесса. Она указывает, как следующая стадия процесса строится из
предыдущей. Нам хотелось бы уметь строить утверждения об общем, или
глобальном (@newterm{global}) поведении процесса, локальная эволюция
которого описана процедурой. В общем случае это сделать очень сложно, но
по крайней мере мы можем попытаться описать некоторые типичные схемы
эволюции процессов.

В этом разделе мы рассмотрим некоторые часто встречающиеся <<формы>>
процессов, генерируемых простыми процедурами. Кроме того, мы рассмотрим,
насколько сильно эти процессы расходуют такие важные вычислительные
ресурсы, как время и память. Процедуры, которые мы будем рассматривать,
весьма просты. Они будут играть такую же роль, как простые схемы в
фотографии: это скорее упрощенные прототипические шаблоны, а не
практические примеры сами по себе.

@menu
* 1-2-1::            Линейные рекурсия и итерация
* 1-2-2::            Древовидная рекурсия
* 1-2-3::            Порядки роста
* 1-2-4::            Возведение в степень
* 1-2-5::            Нахождение наибольшего общего делителя
* 1-2-6::            Пример проверка на простоту
@end menu

@comment @subsection Linear Recursion and Iteration
@subsection Линейные рекурсия и итерация
@node	1.2.1, 1.2.2, 1.2, 1.2

Для начала рассмотрим функцию факториал, определяемую уравнением
@ifinfo

@example
n! = n * (n - 1) * (n - 2) ... 3 * 2 * 1
@end example

@end ifinfo
@tex
$$n! = n \cdot (n - 1) \cdot (n - 2) \cdots 3 \cdot 2 \cdot 1.$$
@end tex
Существует множество способов вычислять факториалы. Один из них
состоит в том, чтобы заметить, что @math{n!} для любого положительного
целого числа @math{n} равен @math{n}, умноженному на @math{(n - 1)!}:
@ifinfo

@example
n! = n * [(n - 1) * (n - 2) ... 3 * 2 * 1] = n * (n - 1)!
@end example

@end ifinfo
@tex
$$n! = n \cdot [(n - 1) \cdot (n - 2) \cdots 3 \cdot 2 \cdot 1] = n \cdot (n - 1)!.$$
@end tex
Таким образом, мы можем вычислить
@math{n!}, вычислив сначала @math{(n - 1)!}, а затем умножив его на
@math{n}. После того, как мы добавляем условие, что @math{1!} равен 1,
это наблюдение можно непосредственно перевести в процедуру:

@lisp
(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
@end lisp

@noindent
Можно использовать подстановочную модель из раздела @ref{1.1.5} и увидеть эту
процедуру в действии при вычислении 6!, как показано на @ref{Рисунок 1.3}.

@float
@quotation
@anchor{Рисунок 1.3}
@ifinfo
@strong{Рисунок 1.3:} Линейно рекурсивный πроцесс для вычисления 6!.

@example
(factorial 6)        ----------------
(* 6 (factorial 5))                   \
(* 6 (* 5 (factorial 4)))               \
(* 6 (* 5 (* 4 (factorial 3))))           \
(* 6 (* 5 (* 4 (* 3 (factorial 2)))))       \
(* 6 (* 5 (* 4 (* 3 (* 2 (factorial 1))))))  |
(* 6 (* 5 (* 4 (* 3 (* 2 1)))))             /
(* 6 (* 5 (* 4 (* 3 2))))                 /
(* 6 (* 5 (* 4 6)))                     /
(* 6 (* 5 24))                        /
(* 6 120)                           /
720          <---------------------
@end example
@end ifinfo
@iftex
@sp 0.4
@center @image{fig/chap1/Fig1.3c,82mm,,,.pdf}
@sp 0.7
@center @caption{@strong{Рисунок 1.3:} Линейно рекурсивный πроцесс для вычисления 6!.}
@sp 1.0
@end iftex
@end quotation
@end float

Теперь рассмотрим вычисление факториала с другой точки зрения. Мы можем
описать правило вычисления @math{n!}, сказав, что мы сначала умножаем 1
на 2, затем результат умножаем на 3, затем на 4, и так пока не
достигнем @math{n}. Мы можем описать это вычисление, сказав, что
счетчик и произведение с каждым шагом одновременно изменяются согласно
правилу

@example
произведение @math{\gets} счетчик * произведение
счетчик @math{\gets} счетчик + 1
@end example

@noindent
и добавив условие, что @math{n!} --- это значение произведения
в тот момент, когда счетчик становится больше, чем @math{n}.

\enlargethispage{\baselineskip}

@float
@quotation
@anchor{Рисунок 1.4}
@ifinfo
@strong{Рисунок 1.4:} Линейно итеративный πроцесс для вычисления 6!.

@example
(factorial 6)   -----.
(fact-iter   1 1 6)  |
(fact-iter   1 2 6)  |
(fact-iter   2 3 6)  |
(fact-iter   6 4 6)  |
(fact-iter  24 5 6)  |
(fact-iter 120 6 6)  |
(fact-iter 720 7 6)  V
720
@end example
@end ifinfo
@iftex
@sp 0.4
@center @image{fig/chap1/Fig1.4c,36mm,,,.pdf}
@sp 0.7
@center @caption{@strong{Рисунок 1.4:} Линейно итеративный πроцесс для вычисления 6!.}
@sp 1.0
@end iftex
@end quotation
@end float

Опять же, мы можем перестроить наше определение в процедуру вычисления
факториала:@footnote{В настоящей программе мы, скорее всего, спрятали бы
определение @code{fact-iter} с помощью блочной структуры, введенной в
предыдущем разделе:

@lisp
(define (factorial n)
  (define (iter product counter)
    (if (> counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))
@end lisp

Здесь мы этого не сделали, чтобы как можно меньше думать о разных вещах
одновременно.}

@lisp
(define (factorial n)
  (fact-iter 1 1 n))
(define (fact-iter product counter max-count)
  (if (> counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))
@end lisp

@noindent
Как и раньше, мы можем с помощью подстановочной модели изобразить
процесс вычисления 6!, как показано на @ref{Рисунок 1.4}.

Сравним эти два процесса. С одной стороны, они кажутся почти
одинаковыми. Оба они вычисляют одну и ту же математическую функцию с
одной и той же областью определения, и каждый из них для вычисления
@math{n!} требует количества шагов, пропорционального @math{n}.
Действительно, два этих процесса даже производят одну и ту же
последовательность умножений и получают одну и ту же
последовательность частичных произведений. С другой стороны, когда мы
рассмотрим <<формы>> этих двух процессов, мы увидим, что они ведут себя
совершенно по-разному

Возьмем первый процесс. Подстановочная модель показывает сначала серию
расширений, а затем сжатие, как показывает стрелка на @ref{Рисунок 1.3}.
Расширение происходит по мере того, как
процесс строит цепочку (@newterm{deferred operations}), в данном случае цепочку
умножений. Сжатие происходит тогда, когда выполняются эти отложенные
операции. Такой тип процесса, который характеризуется цепочкой
отложенных операций, называется (@newterm{recursive process}). Выполнение этого
процесса требует, чтобы интерпретатор запоминал, какие операции ему
нужно выполнить впоследствии. При вычислении @math{n!} длина цепочки
отложенных умножений, а следовательно, и объем информации, который
требуется, чтобы ее сохранить, растет линейно с ростом @math{n}
(пропорционален @math{n}), как и число шагов. Такой процесс называется
(@newterm{linear recursive process}).

Напротив, второй процесс не растет и не сжимается. На каждом шаге при
любом значении @math{n} необходимо помнить лишь текущие значения
переменных @code{product}, @code{counter} и @code{max-count}. Такой
процесс мы называем (@newterm{iterative process}).

В общем случае, итеративный процесс --- это такой процесс, состояние
которого можно описать конечным числом переменных состояния
(@newterm{state variables}) плюс заранее заданное правило, определяющее, как эти
переменные состояния изменяются от шага к шагу, и плюс (возможно) тест
на завершение, который определяет условия, при которых процесс должен
закончить работу. При вычислении @math{n!} число шагов линейно растет с
ростом @math{n}. Такой процесс называется (@newterm{linear iterative process}).

@endpage
Можно посмотреть на различие этих двух процессов и с другой точки
зрения. В итеративном случае в каждый момент переменные программы дают
полное описание состояния процесса. Если мы остановим процесс между
шагами, для продолжения вычислений нам будет достаточно дать
интерпретатору значения трех переменных программы. С рекурсивным
процессом это не так. В этом случае имеется дополнительная
<<спрятанная>> информация, которую хранит интерпретатор и которая не
содержится в переменных программы. Она указывает, <<где находится>>
процесс в терминах цепочки отложенных операций. Чем длиннее цепочка,
тем больше информации нужно хранить.@footnote{Когда в @ref{Глава 5}
мы будем обсуждать реализацию процедур с помощью регистровых машин, мы
увидим, что итеративный процесс можно реализовать <<в аппаратуре>> как
машину, у которой есть только конечный набор регистров и нет никакой
дополнительной памяти. Напротив, для реализации рекурсивного процесса
требуется машина со вспомогательной структурой данных, называемой
(stack).}

Противопоставляя итерацию и рекурсию, нужно вести себя осторожно и не
смешивать понятие рекурсивного процесса (@newterm{process}) с понятием рекурсивной
процедуры @newterm{procedure}. Когда мы говорим, что процедура рекурсивна, мы
имеем в виду факт синтаксиса: определение процедуры ссылается (прямо
или косвенно) на саму эту процедуру. Когда же мы говорим о процессе,
что он следует, скажем, линейно рекурсивной схеме, мы говорим о
развитии процесса, а не о синтаксисе, с помощью которого написана
процедура. Может показаться странным, например, высказывание
<<рекурсивная процедура @code{fact-iter} описывает итеративный
процесс>>. Однако процесс действительно является итеративным: его
состояние полностью описывается тремя переменными состояния, и чтобы
выполнить этот процесс, интерпретатор должен хранить значение только
трех переменных.

\enlargethispage{\baselineskip}

Различие между процессами и процедурами может запутывать отчасти потому,
что большинство реализаций обычных языков (включая Ada, Pascal и C)
построены так, что интерпретация любой рекурсивной процедуры поглощает
объем памяти, линейно растущий пропорционально количеству вызовов
процедуры, даже если описываемый ею процесс в принципе итеративен. Как
следствие, эти языки способны описывать итеративные процессы только с
помощью специальных<<циклических конструкций>> вроде @code{do},
@code{repeat}, @code{until}, @code{for} и @code{while}. Реализация
Scheme, которую мы рассмотрим в @ref{Глава 5},
свободна от этого недостатка. Она будет выполнять итеративный процесс,
используя фиксированный объем памяти, даже если он описывается
рекурсивной процедурой. Такое свойство реализации языка называется
поддержкой (@newterm{tail recursion}). Если реализация языка поддерживает
хвостовую рекурсию, то итерацию можно выразить с помощью обыкновенного
механизма вызова функций, так что специальные циклические конструкции
имеют смысл только как синтаксический сахар.@footnote{Довольно долго
считалось, что хвостовая рекурсия --- особый трюк в оптимизирующих
компиляторах. Ясное семантическое основание хвостовой рекурсии было
найдено Карлом Хьюиттом @ref{(Hewitt 1977}, который выразил ее в терминах
модели вычислений с помощью <<передачи сообщений>> (мы рассмотрим эту
модель в @ref{Глава 3}).
Вдохновленные этим, Джеральд Джей Сассман и Гай Льюис Стил мл. (см.
@ref{Steele and Sussman 1975}) построили интерпретатор Scheme с поддержкой хвостовой
рекурсии. Позднее Стил показал, что хвостовая рекурсия является
следствием естественного способа компиляции вызовов процедур (@ref{Steele 1977}).
Стандарт Scheme @acronym{IEEE} требует, чтобы все реализации Scheme
поддерживали хвостовую рекурсию.}.

@quotation
@strong{@anchor{Упражнение 1.9}Упражнение 1.9:} Каждая из следующих двух
процедур определяет способ сложения
двух положительных целых чисел с помощью процедур @code{inc}, которая
добавляет к своему аргументу 1, и @code{dec}, которая отнимает от
своего аргумента 1.

@lisp
(define (+ a b)
  (if (= a 0) b (inc (+ (dec a) b))))
(define (+ a b)
  (if (= a 0) b (+ (dec a) (inc b))))
@end lisp

Используя подстановочную модель, проиллюстрируйте процесс, порождаемый
каждой из этих процедур, вычислив @code{(+ 4 5)}. Являются ли эти
процессы итеративными или рекурсивными?
@end quotation

@quotation
@strong{@anchor{Упражнение 1.10}Упражнение 1.10:} Следующая процедура
вычисляет математическую функцию, называемую функцией Аккермана.

@lisp
(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1) (A x (- y 1))))))
@end lisp

Каковы значения следующих выражений?

@lisp
(A 1 10)
(A 2 4)
(A 3 3)
@end lisp

Рассмотрим следующие процедуры, где @code{A} --- процедура, определенная
выше:

@lisp
(define (f n) (A 0 n))
(define (g n) (A 1 n))
(define (h n) (A 2 n))
(define (k n) (* 5 n n))
@end lisp

Дайте краткие математические определения функций, вычисляемых
процедурами @code{f}, @code{g} и @code{h} для положительных целых
значений @math{n}. Например, @code{(k n)} вычисляет @math{5n^2}.
@end quotation

@comment @subsection Tree Recursion
@subsection Древовидная рекурсия
@node	1.2.2, 1.2.3, 1.2.1, 1.2

Существует еще одна часто встречающаяся схема вычислений, называемая
древовидная рекурсия (@newterm{tree recursion}). В качестве примера
рассмотрим вычисление последовательности чисел Фибоначчи, в которой
каждое число является суммой двух предыдущих:
@ifinfo
@center 0, 1, 1, 2, 3, 5, 8, 13, 21, @dots{}
@end ifinfo
@tex
$$ 0,\; 1,\; 1,\; 2,\; 3,\; 5,\; 8,\; 13,\; 21,\; \dots. $$
@end tex
Общее правило для чисел Фибоначчи можно сформулировать так:
@ifinfo

@example
         /
         |  0                        if n = 0
Fib(n) = <  1                        if n = 1
         |  Fib(n - 1) + Fib(n - 2)  otherwise
         \
@end example

@end ifinfo
@tex
$$ {\rm Fib}(n) =
\begin{cases}
        \; 0 & {\rm if} \;\; n=0, \\
	\; 1 & {\rm if} \;\; n=1, \\
	\; {\rm Fib}(n-1) + {\rm Fib}(n-2) \quad & {\rm otherwise}.
\end{cases} $$
@end tex
Можно немедленно преобразовать это определение в процедуру:

@lisp
(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
@end lisp

@noindent
Рассмотрим схему этого вычисления. Чтобы вычислить @code{(fib 5)}, мы
сначала вычисляем @code{(fib 4)} и @code{(fib 3)}. Чтобы вычислить
@code{(fib 4)}, мы вычисляем @code{(fib 3)} и @code{(fib 2)}. В общем,
получающийся процесс похож на дерево, как показано на
рис. @ref{Рисунок 1.5}. Заметьте, что на каждом уровне (кроме дна)
ветви разделяются надвое; это отражает тот факт, что процедура
@code{fib} при каждом вызове обращается к самой себе дважды.

Эта процедура полезна как пример прототипической древовидной рекурсии,
но как метод получения чисел Фибоначчи она ужасна, поскольку производит
массу излишних вычислений. Обратите внимание на
рис. @ref{Рисунок 1.5}: все вычисление @code{(fib 3)} --- почти
половина общей работы, --- повторяется дважды. В сущности, нетрудно
показать, что общее число раз, которые эта процедура вызовет
@code{(fib 1)} или @code{(fib 0)} (в общем, число листьев) в точности
равняется Fib(@math{n+1}). Чтобы понять, насколько это
плохо, отметим, что значение Fib(@math{n}) растет экспоненциально при
увеличении @math{n}. Более точно (см. в @ref{Упражнение 1.13}),
Fib(@math{n}) --- это целое число, ближайшее к @math{\varphi^n / \sqrt{5}}, где
@ifinfo

@example
[phi] = (1 + [sqrt]5)/2 ~= 1.6180
@end example

@end ifinfo
@tex
$$\varphi = {1 + \sqrt{5}\over2} \approx 1.6180 $$
@end tex
@noindent
есть золотое сечение (@newterm{golden ratio}), которое удовлетворяет уравнению
@ifinfo

@example
[phi]^2 = [phi] + 1
@end example

@end ifinfo
@tex
$$\varphi^2 = \varphi + 1. $$
@end tex

@float
@quotation
@anchor{Рисунок 1.5}
@ifinfo
@strong{Рисунок 1.5:} Древовидно-рекурсивный πроцесс, πорождаемый πри вычислении @code{(fib 5)}.

@example

                   ..<............ fib5   <..........
                ...     ___________/  \___________   .
             ...       /       . .....            \    .
           ..       fib4     .        . . . .     fib3  .
         ..     ____/. \____  ..             .  __/  \__  .
       ..      /  . .  ..   \    .        ..   /  . .   \   .
     ..     fib3 .       .  fib2 .        . fib2 .   .  fib1 .
   ..      / . \  .     .   /  \  .      .  /  \ ...  .  |  .
 ..       / . . \   .  .   /  . \   .  .   / .  \   .  . 1 .
.      fib2 . . fib1.  .fib1 .  fib0 . .fib1. . fib0 .  .  .
.      /  \  . . |  .  . |  .  . |   . . |   . . |   .   .>
V     /  . \   . 1  .  . 1  .  . 0  .  . 1  .  . 0  ..
.  fib1 .. fib0..  .   .   .   .   .   V   .   ..  .
.   |  .  . |  . .>     .>.     . .    ..>.      .>
.   1 .   . 0  .
 .   .     .  .
  .>.       ..

@end example
@end ifinfo
@iftex
@sp 0.3
@center @image{fig/chap1/Fig1.5c,90mm,,,.pdf}
@sp 0.5
@caption{@strong{Рисунок 1.5:} Древовидно-рекурсивный πроцесс, πорождаемый πри вычислении @code{(fib 5)}.}
@sp 0.0
@end iftex
@end quotation
@end float

@noindent
Таким образом, число шагов нашего процесса
растет экспоненциально при увеличении аргумента. С другой стороны,
требования к памяти растут при увеличении аргумента всего лишь линейно,
поскольку в каждой точке вычисления нам требуется запоминать только те
вершины, которые находятся выше нас по дереву. В общем случае число
шагов, требуемых древовидно-рекурсивным процессом, будет пропорционально
числу вершин дерева, а требуемый объем памяти будет пропорционален
максимальной глубине дерева.

Для получения чисел Фибоначчи мы можем сформулировать итеративный
процесс. Идея состоит в том, чтобы использовать пару целых @math{a} и
@math{b}, которым в начале даются значения
Fib(1) = 1 и Fib(0) = 0, и на каждом шаге применять одновременную трансформацию
@ifinfo

@example
a <- a + b
b <- a
@end example

@end ifinfo
@tex
$$
\begin{array}{l@{\;\;\gets\;\;}l}
  a & a + b, \\
  b & a.
\end{array}
$$
@end tex
@noindent
Нетрудно показать, что после того, как мы проделаем эту
трансформацию @math{n} раз, @math{a} и @math{b} будут соответственно
равны Fib(@math{n + 1}) и Fib(@math{n}).
Таким образом, мы можем итеративно вычислять числа Фибоначчи при помощи
процедуры

@lisp
(define (fib n)
  (fib-iter 1 0 n))
(define (fib-iter a b count)
  (if (= count 0)
      b
      (fib-iter (+ a b) a (- count 1))))
@end lisp

@noindent
Второй метод вычисления чисел Фибоначчи представляет собой линейную
итерацию. Разница в числе шагов, требуемых двумя этими методами ---
один пропорционален @math{n}, другой растет так же быстро, как и само
Fib(@math{n}), --- огромна, даже для небольших значений аргумента.

Не нужно из этого делать вывод, что древовидно-рекурсивные процессы
бесполезны. Когда мы будем рассматривать процессы, работающие не с
числами, а с иерархически структурированными данными, мы увидим, что
древовидная рекурсия является естественным и мощным
инструментом.@footnote{Пример этого был упомянут в
разделе @ref{1.1.3}: сам интерпретатор
вычисляет выражения с помощью древовидно-рекурсивного процесса.} Но
даже при работе с числами древовидно-рекурсивные процессы могут быть
полезны --- они помогают нам понимать и проектировать программы.
Например, хотя первая процедура @code{fib} и намного менее эффективна,
чем вторая, зато она проще, поскольку это немногим более, чем перевод
определения последовательности чисел Фибоначчи на Лисп. Чтобы
сформулировать итеративный алгоритм, нам пришлось заметить, что
вычисление можно перестроить в виде итерации с тремя переменными
состояния.

@comment @subsubheading Example: Counting change
@subsubheading Пример: Размен денег

Чтобы сочинить итеративный алгоритм для чисел Фибоначчи, нужно совсем
немного смекалки. Теперь для контраста рассмотрим следующую задачу:
сколькими способами можно разменять сумму в 1 доллар, если имеются
монеты по 50, 25, 10, 5 и 1 цент? В более общем случае, можно ли
написать процедуру подсчета способов размена для произвольной суммы
денег?

У этой задачи есть простое решение в виде рекурсивной процедуры.
Предположим, мы как-то упорядочили типы монет, которые у нас есть. В
таком случае верно будет следующее уравнение:

Число способов разменять сумму @math{a} с помощью @math{n} типов монет
равняется

@itemize @bullet

@item
числу способов разменять сумму @math{a} с помощью всех типов монет,
кроме первого, плюс

@item
число способов разменять сумму @math{a - d} с использованием всех @math{n}
типов монет, где @math{d} --- достоинство монет первого типа.

@end itemize

@noindent
Чтобы увидеть, что это именно так, заметим, что способы размена могут
быть поделены на две группы: те, которые не используют первый тип
монеты, и те, которые его используют. Следовательно, общее число
способов размена какой-либо суммы равно числу способов разменять эту
сумму без привлечения монет первого типа плюс число способов размена в
предположении, что мы этот тип используем. Но последнее число равно
числу способов размена для суммы, которая остается после того, как мы
один раз употребили первый тип монеты.

Таким образом, мы можем рекурсивно свести задачу размена данной суммы к
задаче размена меньших сумм с помощью меньшего количества типов монет.
Внимательно рассмотрите это правило редукции и убедите себя, что мы
можем использовать его для описания алгоритма, если укажем следующие
вырожденные случаи:@footnote{Рассмотрите для примера в деталях, как
применяется правило редукции, если нужно разменять 10 центов на
монеты в 1 и 5 центов.}

@itemize @bullet

@item
Если @math{a} в точности равно 0, мы считаем, что имеем 1 способ размена.

@item
Если @math{a} меньше 0, мы считаем, что имеем 0 способов размена.

@item
Если @math{n} равно 0, мы считаем, что имеем 0 способов размена.

@end itemize

@noindent
Это описание легко перевести в рекурсивную процедуру:

@lisp
(define (count-change amount) (cc amount 5))
(define (cc amount kinds-of-coins)
  (cond ((= amount 0) 1)
        ((or (< amount 0) (= kinds-of-coins 0)) 0)
        (else (+ (cc amount
                     (- kinds-of-coins 1))
                 (cc (- amount
                        (first-denomination
                         kinds-of-coins))
                     kinds-of-coins)))))
(define (first-denomination kinds-of-coins)
  (cond ((= kinds-of-coins 1) 1)
        ((= kinds-of-coins 2) 5)
        ((= kinds-of-coins 3) 10)
        ((= kinds-of-coins 4) 25)
        ((= kinds-of-coins 5) 50)))
@end lisp

@noindent
(Процедура @code{first-denomination} принимает в качестве входа число
доступных типов монет и возвращает достоинство первого типа. Здесь мы
упорядочили монеты от самой крупной к более мелким, но годился бы и
любой другой порядок.) Теперь мы можем ответить на исходный вопрос о
размене доллара:

@lisp
(count-change 100)
@i{292}
@end lisp

@noindent
@code{count-change} порождает древовидно-рекурсивный процесс с
избыточностью, похожей на ту, которая возникает в нашей первой
реализации @code{fib}. (На то, чтобы получить ответ 292, уйдет заметное
время.) С другой стороны, неочевидно, как построить более эффективный
алгоритм для получения этого результата, и мы оставляем это в качестве
задачи для желающих. Наблюдение, что древовидная рекурсия может быть
весьма неэффективна, но зато ее часто легко сформулировать и понять,
привело исследователей к мысли, что можно получить лучшее из двух
миров, если спроектировать <<умный компилятор>>, который мог бы
трансформировать древовидно-рекурсивные процедуры в более эффективные,
но вычисляющие тот же результат.@footnote{Один из способов избежать
избыточных вычислений состоит в том, чтобы автоматически строить
таблицу значений по мере того, как они вычисляются. Каждый раз, когда
нужно применить процедуру к какому-нибудь аргументу, мы могли бы
сначала обращаться к таблице, смотреть, не хранится ли в ней уже
значение, и в этом случае мы избежали бы избыточного вычисления. Такая
стратегия, называемая (@newterm{tabulation}) или (@newterm{memoization}), легко реализуется.
Иногда с помощью табуляризации можно преобразовать процессы, требующие
экспоненциального числа шагов (вроде @code{count-change}), в процессы,
требования которых к времени и памяти линейно растут по мере роста
ввода. См. @ref{Упражнение 3.27}.}

@quotation
@strong{@anchor{Упражнение 1.11}Упражнение 1.11:} Функция @math{f}
определяется правилом:
@tex
$$
f(n) =
\begin{cases}
\;\; n \quad \text{if \; \( n < 3 \),} \\
\;\; f(n-1) + 2\kern-0.08em f(n-2) + 3\kern-0.08em f(n-3) \quad \text{if \; \( n \ge 3 \).}
\end{cases}
$$
@end tex
Напишите процедуру, вычисляющую
@math{f} с помощью рекурсивного процесса. Напишите процедуру,
вычисляющую @math{f} с помощью итеративного процесса.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.12}Упражнение 1.12:} Приведенная ниже таблица называется триугольник Паскаля (@newterm{Pascal's triangle}).

@example
        1
      1   1
    1   2   1
  1   3   3   1
1   4   6   4   1
      . . .
@end example

Все числа по краям треугольника равны 1, а каждое число
внутри треугольника равно сумме двух чисел над ним.@footnote{Элементы
треугольника Паскаля называются (@newterm{binomial coefficients}), поскольку
@math{n}-й ряд состоит из коэффициентов термов при разложении
@math{(x + y)^n}. Эта схема вычисления коэффициентов появилась в
передовой работе Блеза Паскаля 1653 года по теории вероятностей
@cite{Trait@'e dutriangle arithm@'etique}. Согласно @ref{Knuth (1973)}, та же схема
встречается в труде @emph{Цзу-юань Юй-чэнь} (<<Драгоценное зеркало
четырех элементов>>), опубликованном китайским математиком Цзю Ши-Цзе в
1303 году, в трудах персидского поэта и математика двенадцатого века
Омара Хайяма и в работах индийского математика двенадцатого века
Бхаскары Ачарьи.} Напишите процедуру, вычисляющую элементы треугольника
Паскаля с помощью рекурсивного процесса.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.13}Упражнение 1.13:} Докажите, что Fib(@math{n})
есть целое число, ближайшее к @math{\varphi^n / \sqrt{5}}, где @math{\varphi = (1 + \sqrt{5}) / 2}.  Указание: пусть @math{\psi = (1 - \sqrt{5}) / 2}.
С помощью определения чисел Фибоначчи (см. @ref{1.2.2}) и индукции докажите,
что @math{\text{Fib}(n) = (\varphi^n - \psi^n) / \sqrt{5}}.
@end quotation

@comment @subsection Orders of Growth
@subsection Порядки роста
@node	1.2.3, 1.2.4, 1.2.2, 1.2

Предшествующие примеры показывают, что процессы могут значительно
различаться по количеству вычислительных ресурсов, которые они
потребляют. Удобным способом описания этих различий является понятие
(@newterm{order of growth}), которое дает общую оценку ресурсов, необходимых
процессу при увеличении его входных данных.

Пусть @math{n} --- параметр, измеряющий размер задачи, и пусть
@math{R(n)} --- количество ресурсов, необходимых процессу для решения
задачи размера @math{n}. В предыдущих примерах @math{n} было числом, для
которого требовалось вычислить некоторую функцию, но возможны и другие
варианты. Например, если требуется вычислить приближение к квадратному
корню числа, то @math{n} может быть числом цифр после запятой, которые
нужно получить. В задаче умножения матриц @math{n} может быть
количеством рядов в матрицах. Вообще говоря, может иметься несколько
характеристик задачи, относительно которых желательно проанализировать
данный процесс. Подобным образом, @math{R(n)} может измерять количество
используемых целочисленных регистров памяти, количество исполняемых
элементарных машинных операций, и так далее. В компьютерах, которые
выполняют определенное число операций за данный отрезок времени,
требуемое время будет пропорционально необходимому числу элементарных
машинных операций.

Мы говорим, что @math{R(n)} имеет порядок роста @math{\Theta(f(n))}, что
записывается @math{R(n) = \Theta(f(n))} и произносится <<тета от @math{f(n)}>>,
если существуют положительные постоянные @math{k_1} и @math{k_2}, независимые
от @math{n}, такие, что @math{k_1 f(n) \le R(n) \le k_2f(n)} для всякого
достаточно большого @math{n}. (Другими словами, значение @math{R(n)}
заключено между @math{k_1f(n)} и @math{k_2f(n)}.)

\enlargethispage{\baselineskip}

Например, для линейно рекурсивного процесса вычисления факториала,
описанного в разделе @ref{1.2.1},
число шагов растет пропорционально входному значению @math{n}. Таким
образом, число шагов, необходимых этому процессу, растет как
@math{\Theta(n)}. Мы видели также, что требуемый объем памяти растет как
@math{\Theta(n)}. Для итеративного факториала число шагов по-прежнему
@math{\Theta(n)}, но объем памяти @math{\Theta(1)} --- то есть
константа.@footnote{В этих утверждениях скрывается важное упрощение.
Например, если мы считаем шаги процесса как <<машинные операции>>, мы
предполагаем, что число машинных операций, нужных, скажем, для
вычисления произведения, не зависит от размера умножаемых чисел, а это
становится неверным при достаточно больших числах. Те же замечания
относятся и к оценке требуемой памяти. Подобно проектированию и
описанию процесса, анализ процесса может происходить на различных
уровнях абстракции.} Древовидно-рекурсивное вычисление чисел Фибоначчи
требует @math{\Theta(\phi^n)} шагов и @math{\Theta(n)} памяти, где
@math{\phi} --- золотое сечение, описанное в
разделе @ref{1.2.2}.

Порядки роста дают всего лишь грубое описание поведения процесса.
Например, процесс, которому требуется @math{n^2} шагов, процесс,
которому требуется @math{1000n^2} шагов и процесс, которому требуется
@math{3n^2 + 10n + 17} шагов --- все имеют порядок роста
@math{\Theta(n^2)}. С другой стороны, порядок роста показывает, какого
изменения можно ожидать в поведении процесса, когда мы меняем размер
задачи. Для процесса с порядком роста @math{\Theta(n)} (линейного)
удвоение размера задачи примерно удвоит количество используемых
ресурсов. Для экспоненциального процесса каждое увеличение размера
задачи на единицу будет умножать количество ресурсов на постоянный
коэффициент. В оставшейся части раздела @ref{1.2} мы
рассмотрим два алгоритма, которые имеют логарифмический порядок роста,
так что удвоение размера задачи увеличивает требования к ресурсам на
постоянную величину.
@endpage

@quotation
@strong{@anchor{Упражнение 1.14}Упражнение 1.14:} Нарисуйте дерево,
иллюстрирующее процесс, который порождается процедурой @code{count-change} из
раздела @ref{1.2.2} при размене 11 центов. Каковы
порядки роста памяти и числа шагов, используемых этим процессом при
увеличении суммы, которую требуется разменять?
@end quotation

@quotation
@strong{@anchor{Упражнение 1.15}Упражнение 1.15:} Синус угла (заданного
в радианах) можно вычислить, если
воспользоваться приближением @w{@math{\sin x \approx x}} при малых
@math{x} и употребить тригонометрическое тождество

@ifinfo

@example
               x             x
sin x = 3 sin --- - 4 sin^3 ---
               3             3
@end example

@end ifinfo
@tex
$$\sin x = 3\sin {x\over3} - 4\sin^3 {x\over3} $$
@end tex
@noindent
для уменьшения значения аргумента sin. (В этом упражнении мы будем
считать, что угол <<достаточно мал>>, если он не больше 0.1 радиана.)
Эта идея используется в следующих процедурах:

@lisp
(define (cube x) (* x x x))
(define (p x) (- (* 3 x) (* 4 (cube x))))
(define (sine angle)
   (if (not (> (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
@end lisp

@enumerate a.

@item
Сколько раз вызывается процедура @code{p} при вычислении @code{(sine 12.15)}?

@item
Каковы порядки роста в терминах количества шагов и используемой памяти
(как функция @math{a}) для процесса, порождаемого процедурой @code{sine}
при вычислении @code{(sine a)}?

@end enumerate
@end quotation

@comment @subsection Exponentiation
@subsection Возведение в степень
@node	1.2.4, 1.2.5, 1.2.3, 1.2

Рассмотрим задачу возведения числа в степень. Нам нужна процедура,
которая, приняв в качестве аргумента основание @math{b} и положительное
целое значение степени @math{n}, возвращает @math{b^n}. Один из способов
получить желаемое --- через рекурсивное определение
@ifinfo

@example
b^n = b * b^(n - 1)
b^0 = 1
@end example

@end ifinfo
@tex
$$
\begin{array}{l@{{}={}}l}
  b^n & b\cdot b^{n-1}, \\
  b^0 & 1,
\end{array}
$$
@end tex
которое прямо переводится в процедуру

@lisp
(define (expt b n)
  (if (= n 0)
      1
      (* b (expt b (- n 1)))))
@end lisp

@noindent
Это линейно рекурсивный процесс, требующий @math{\Theta(n)} шагов и
@math{\Theta(n)} памяти. Подобно факториалу, мы можем немедленно
сформулировать эквивалентную линейную итерацию:

@lisp
(define (expt b n)
  (expt-iter b n 1))
(define (expt-iter b counter product)
  (if (= counter 0)
      product
      (expt-iter b
                 (- counter 1)
                 (* b product))))
@end lisp

@noindent
Эта версия требует @math{\Theta(n)} шагов и @math{\Theta(1)} памяти.

Можно вычислять степени за меньшее число шагов, если использовать
последовательное возведение в квадрат. Например, вместо того, чтобы
вычислять @math{b^8} в виде
@ifinfo

@example
b * (b * (b * (b * (b * (b * (b * b))))))
@end example

@end ifinfo
@tex
$$ b\cdot (b\cdot (b\cdot (b\cdot (b\cdot (b\cdot (b\cdot b))))))\,, $$
@end tex
мы можем вычислить его за три умножения:
@ifinfo

@example
b^2 = b * b
b^4 = b^2 * b^2
b^8 = b^4 * b^4
@end example

@end ifinfo
@tex
$$
\begin{array}{l@{{}={}}l}
  b^2 & b\cdot b, \\
  b^4 & b^2\cdot b^2, \\
  b^8 & b^4\cdot b^4.
\end{array}
$$
@end tex
Этот метод хорошо работает для степеней, которые сами являются степенями
двойки. В общем случае при вычислении степеней мы можем получить
преимущество от последовательного возведения в квадрат, если
воспользуемся правилом
@ifinfo

@example
b^n = (b^(n/2))^2    если n четно
b^n = b * b^(n - 1)  если n нечетно
@end example

@end ifinfo
@tex
$$
\begin{array}{l@{{}={}}lr@{\ n\ }l}
  b^n & (b^{n / 2})^2  \;\; & \mbox{Если\,} & \mbox{\,четно}, \\
  b^n & b\cdot b^{n-1} \;\; & \mbox{if\,} & \mbox{\,нечетно}.
\end{array}
$$
@end tex
Этот метод можно выразить в виде процедуры

@lisp
(define (fast-expt b n)
  (cond ((= n 0) 1)
        ((even? n) (square (fast-expt b (/ n 2))))
        (else (* b (fast-expt b (- n 1))))))
@end lisp

@noindent
где предикат, проверяющий целое число на четность, определен через
элементарную процедуру @code{remainder}:

@lisp
(define (even? n)
  (= (remainder n 2) 0))
@end lisp

@noindent
Процесс, вычисляющий @code{fast-expt}, растет логарифмически как по
используемой памяти, так и по количеству шагов. Чтобы увидеть это,
заметим, что вычисление @math{b^{2n}} с помощью этого алгоритма требует
всего на одно умножение больше, чем вычисление @math{b^n}.
Следовательно, размер степени, которую мы можем вычислять, возрастает
примерно вдвое с каждым следующим умножением, которое нам разрешено
делать. Таким образом, число умножений, требуемых для вычисления степени
@math{n}, растет приблизительно так же быстро, как логарифм @math{n} по
основанию 2. Процесс имеет степень роста
@math{\Theta(\log(n))}.@footnote{Точнее, количество требуемых умножений
равно логарифму @math{n} по основанию 2 минус 1 и плюс количество
единиц в двоичном представлении @math{n}. Это число всегда меньше, чем
удвоенный логарифм @math{n} по основанию 2. Произвольные константы
@math{k_1} и @math{k_2} в определении порядка роста означают, что для
логарифмического процесса основание, по которому берется логарифм, не
имеет значения, так что все такие процессы описываются как
@math{\Theta(\log(n))}.}

Если @math{n} велико, разница между порядком роста
@math{\Theta(\log(n))} и @math{\Theta(n)} оказывается очень заметной.
Например, @code{fast-expt} при @math{n = 1000} требует всего 14
умножений.@footnote{Если Вас интересует, зачем это кому-нибудь может
понадобиться возводить числа в 1000-ю степень, смотрите
раздел @ref{1.2.6}.} С помощью идеи
последовательного возведения в квадрат можно построить также
итеративный алгоритм, который вычисляет степени за логарифмическое число
шагов (см. @ref{Упражнение 1.16}), хотя, как это часто
бывает с итеративными алгоритмами, его нельзя записать так же просто,
как рекурсивный алгоритм.@footnote{Итеративный алгоритм очень стар. Он
встречается в @cite{Чанда-сутре} Ачарьи Пингалы, написанной до 200 года
до н.э. В @ref{Knuth (1981)}, раздел 4.6.3, содержится полное обсуждение и
анализ этого и других методов возведения в степень.}

@quotation
@strong{@anchor{Упражнение 1.16}Упражнение 1.16:} Напишите процедуру,
которая развивается в виде
итеративного процесса и реализует возведение в степень за
логарифмическое число шагов, как @code{fast-expt}. (Указание: используя
наблюдение, что @math{(b^{n / 2})^2 = (b^2)^{n / 2}}, храните, помимо
значения степени @math{n} и основания @math{b}, дополнительную
переменную состояния @math{a}, и определите переход между состояниями
так, чтобы произведение @math{ab^n} от шага к шагу не менялось. Вначале
значение @math{a} берется равным 1, а ответ получается как значение
@math{a} в момент окончания процесса. В общем случае метод определения
(@newterm{invariant quantity}), который не изменяется при переходе между
шагами, является мощным способом размышления о построении итеративных
алгоритмов.)
@end quotation

@quotation
@strong{@anchor{Упражнение 1.17}Упражнение 1.17:} Алгоритмы возведения
в степень из этого раздела основаны
на повторяющемся умножении. Подобным же образом можно производить
умножение с помощью повторяющегося сложения. Следующая процедура
умножения (в которой предполагается, что наш язык способен только
складывать, но не умножать) аналогична процедуре @code{expt}:

@lisp
(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))
@end lisp

Этот алгоритм затрачивает количество шагов, линейно пропорциональное
@code{b}. Предположим теперь, что, наряду со сложением, у нас есть
операции @code{double}, которая удваивает целое число, и @code{halve},
которая делит (четное) число на 2. Используя их, напишите процедуру,
аналогичную @code{fast-expt}, которая затрачивает логарифмическое число
шагов.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.18}Упражнение 1.18:} Используя результаты
@ref{Упражнение 1.16} и @ref{Упражнение 1.17}, разработайте
процедуру, которая порождает
итеративный процесс для умножения двух чисел с помощью сложения,
удвоения и деления пополам, и затрачивает логарифмическое число
шагов.@footnote{Этот алгоритм, который иногда называют <<методом русского
крестьянина>>, очень стар. Примеры его использования найдены в Риндском
папирусе, одном из двух самых древних существующих математических
документов, который был записан (и при этом скопирован с еще более
древнего документа) египетским писцом по имени А'х-мосе около 1700 г. до
н.э.}
@end quotation

\enlargethispage{\baselineskip}

@quotation
@strong{@anchor{Упражнение 1.19}Упражнение 1.19:} Существует
хитрый алгоритм получения чисел Фибоначчи за
логарифмическое число шагов. Вспомните трансформацию переменных
состояния @math{a} и @math{b} процесса @code{fib-iter} из
раздела @ref{1.2.2}: @math{a \gets a+b} и
@math{b \gets a}. Назовем эту трансформацию @math{T} и заметим, что
@math{n}-кратное применение @math{T}, начиная с 1 и 0, дает нам пару
Fib(@math{n+1} и Fib(@math{n}. Другими
словами, числа Фибоначчи получаются путем применения @math{T^n},
@math{n}-ой степени трансформации @math{T}, к паре (1,0). Теперь
рассмотрим @math{T} как частный случай @math{p = 0, q =
1} в семействе трансформаций @math{T_{pq}}, где @math{T_{pq}}
преобразует пару @math{(a,b)} по правилу
@math{a \gets bq + aq + ap} и @math{b \gets bp + aq}. Покажите, что двукратное
применение трансформации @math{T_{pq}} равносильно однократному
применению трансформации @math{T_{p'\!q'}} того же типа, и вычислите
@math{p'\!} и @math{q'\!} через @math{p} и @math{q}. Это дает нам прямой
способ возводить такие трансформации в квадрат, и таким образом, мы
можем вычислить @math{T^n} с помощью последовательного возведения в
квадрат, как в процедуре @code{fast-expt}. Используя все эти идеи,
завершите следующую процедуру, которая дает результат за логарифмическое
число шагов:@footnote{Это упражнение нам предложил Джо Стой на основе
примера из @ref{Kaldewaij 1990}.}

@lisp
(define (fib n)
  (fib-iter 1 0 0 1 n))
(define (fib-iter a b p q count)
  (cond ((= count 0) b)
        ((even? count)
         (fib-iter a
                   b
                   @math{\langle}??@math{\rangle}   @r{; вычислить @math{p'}}
                   @math{\langle}??@math{\rangle}   @r{; вычислить @math{q'}}
                   (/ count 2)))
        (else (fib-iter (+ (* b q) (* a q) (* a p))
                        (+ (* b p) (* a q))
                        p
                        q
                        (- count 1)))))
@end lisp
@end quotation

@comment @subsection Greatest Common Divisors
@subsection Нахождение наибольшего общего делителя
@node	1.2.5, 1.2.6, 1.2.4, 1.2

По определению, наибольший общий делитель (НОД) двух целых чисел
@math{a} и @math{b} --- это наибольшее целое число, на которое и
@math{a}, и @math{b} делятся без остатка. Например, НОД 16 и 28 равен
4. В @ref{Глава 2},
когда мы будем исследовать реализацию арифметики на рациональных числах,
нам потребуется вычислять НОДы, чтобы сокращать дроби. (Чтобы сократить
дробь, нужно поделить ее числитель и знаменатель на их НОД. Например,
16/28 сокращается до 4/7.) Один из способов найти НОД двух чисел состоит
в том, чтобы разбить каждое из них на простые множители и найти среди
них общие, однако существует знаменитый и значительно более эффективный
алгоритм.

Этот алгоритм основан на том, что если @math{r} есть остаток от деления
@math{a} на @math{b}, то общие делители @math{a} и @math{b} в точности
те же, что и общие делители @math{b} и @math{r}. Таким образом, можно
воспользоваться уравнением

@example
НОД(a,b) = НОД(b,r)
@end example

@noindent
чтобы последовательно свести задачу нахождения НОД к задаче нахождения НОД
все меньших и меньших пар целых чисел. Например,

@example
НОД(206,40) = НОД(40,6)
            = НОД(6,4)
            = НОД(4,2)
            = НОД(2,0)
            = 2
@end example

@noindent
сводит НОД(206, 40) к НОД(2, 0), что равняется двум. Можно показать,
что если начать с произвольных двух целых чисел и производить
последовательные редукции, в конце концов всегда получится пара, где
вторым элементом будет 0. Этот способ нахождения НОД известен как
(@newterm{Euclid's Algorithm}).@footnote{Алгоритм Евклида называется так потому,
что он встречается в @cite{Началах} Евклида (книга 7, ок. 300 г. до
н.э.). По утверждению Кнута @ref{Knuth (1973)}, его можно считать самым старым
из известных нетривиальных алгоритмов. Древнеегипетский метод умножения
(@ref{Упражнение 1.18}), разумеется, древнее, но, как
объясняет Кнут, алгоритм Евклида --- самый старый алгоритм,
представленный в виде общей процедуры, а не через набор иллюстрирующих
примеров.}

Алгоритм Евклида легко выразить в виде процедуры:

@lisp
(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
@end lisp

@noindent
Она порождает итеративный процесс, число шагов которого растет
пропорционально логарифму чисел-аргументов.

Тот факт, что число шагов, затрачиваемых алгоритмом Евклида, растет
логарифмически, интересным образом связан с числами Фибоначчи:

@quotation
@strong{Теорема Ламэ:}

Если алгоритму Евклида требуется @math{k} шагов для вычисления НОД
некоторой пары чисел, то меньший из членов этой пары больше или равен
@math{k}-тому числу Фибоначчи.@footnote{Эту теорему доказал в 1845 году
Габриэль Ламэ, французский математик и инженер, который больше всего
известен своим вкладом в математическую физику. Чтобы доказать теорему,
рассмотрим пары @math{(a_k, b_k)}, где @math{a_k \ge b_k} и алгоритм
Евклида завершается за @math{k} шагов. Доказательство основывается на
утверждении, что если
@math{(a_{k+1}, b_{k+1}) \to (a_k, b_k) \to (a_{k-1},
b_{k-1})} --- три последовательные пары в процессе редукции, то
@math{b_{k+1} \ge b_k + b_{k-1}}. Чтобы доказать это утверждение,
вспомним, что шаг редукции определяется применением трансформации
@math{a_{k-1} = b_k, b_{k-1} =} остаток от деления @math{a_k} на
@math{b_k}. Второе из этих уравнений означает, что
@math{a_k = qb_k + b_{k-1}} для некоторого положительного числа
@math{q}. Поскольку @math{q} должно быть не меньше 1, имеем
@math{a_k = qb_k + b_{k-1} \ge b_k +
b_{k-1}}. Но из предыдущего шага редукции мы имеем @math{b_{k+1} = a_k}.
Таким образом, @math{b_{k+1} = a_k \ge b_k 
+ b_{k-1}}. Промежуточное утверждение доказано. Теперь можно доказать
теорему индукцией по @math{k}, то есть числу шагов, которые требуются
алгоритму для завершения. Утверждение теоремы верно при @math{k = 1},
поскольку при этом требуется всего лишь чтобы @math{b} было не меньше,
чем Fib(1) = 1. Теперь предположим, что утверждение верно для всех чисел,
меньших или равных @math{k}, и докажем его для @math{k + 1}. Пусть
@math{(a_{k+1}, b_{k+1}) \to (a_k, b_k) \to (a_{k-1}, b_{k-1})} ---
последовательные пары в процессе редукции. Согласно гипотезе индукции,
@math{b_{k-1} \ge {\rm Fib}(k - 1), b_k \ge {\rm Fib} (k)}. Таким образом,
применение промежуточного
утверждения совместно с определением чисел Фибоначчи дает
@math{b_{k+1} \ge b_k + b_{k-1} \ge {\rm Fib}(k) + {\rm
Fib}(k-1) = {\rm Fib} (k+1)}, что и доказывает теорему Ламэ.}
@end quotation

@noindent
С помощью этой теоремы можно оценить порядок роста алгоритма Евклида.
Пусть @math{n} будет меньшим из двух аргументов процедуры. Если процесс
завершается за @math{k} шагов, должно выполняться
@math{n \ge {\rm Fib} (k) \approx
\phi^k / \sqrt{5}}. Следовательно, число шагов @math{k} растет как
логарифм @math{n} (по основанию @math{\varphi}). Следовательно, порядок
роста равен @math{\Theta(\log n)}.

@quotation
@strong{@anchor{Упражнение 1.20}Упражнение 1.20:} Процесс, порождаемый
процедурой, разумеется, зависит от того, по
каким правилам работает интерпретатор. В качестве примера рассмотрим
итеративную процедуру @code{gcd}, приведенную выше. Предположим, что мы
вычисляем эту процедуру с помощью нормального порядка, описанного в
разделе @ref{1.1.5}. (Правило нормального
порядка вычислений для @code{if} описано в
упражнении @ref{Упражнение 1.5}.) Используя подстановочную модель для
нормального порядка, проиллюстрируйте процесс, порождаемый при
вычислении @code{(gcd 206 40)} и укажите, какие операции вычисления
остатка действительно выполняются. Сколько операций @code{remainder}
выполняется на самом деле при вычислении @code{(gcd 206 40)} в
нормальном порядке? При вычислении в аппликативном порядке?
@end quotation

@comment @subsection Example: Testing for Primality
@subsection Пример: проверка на простоту
@node	1.2.6,  , 1.2.5, 1.2

В этом разделе описываются два метода проверки числа @math{n} на
простоту, один с порядком роста @math{\Theta
(\sqrt{n})}, и другой, <<вероятностный>>, алгоритм с порядком роста
@math{\Theta(\log n)}. В упражнениях, приводимых в конце раздела,
предлагаются программные проекты на основе этих алгоритмов.

@comment @subsubheading Searching for divisors
@subsubheading Поиск делителей

С древних времен математиков завораживали проблемы, связанные с
простыми числами, и многие люди занимались поисками способов выяснить,
является ли число простым. Один из способов проверки числа на простоту
состоит в том, чтобы найти делители числа. Следующая программа находит
наименьший целый делитель (больший 1) числа @math{n}. Она проделывает
это <<в лоб>>, путем проверки делимости @math{n} на все последовательные
числа, начиная с 2.

@lisp
(define (smallest-divisor n) (find-divisor n 2))
(define (find-divisor n test-divisor)
  (cond ((> (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (+ test-divisor 1)))))
(define (divides? a b) (= (remainder b a) 0))
@end lisp

@noindent
Мы можем проверить, является ли число простым, следующим образом:
@math{n} простое тогда и только тогда, когда @math{n} само является
своим наименьшим делителем.

@lisp
(define (prime? n)
  (= n (smallest-divisor n)))
@end lisp

@noindent
Тест на завершение основан на том, что если число @math{n} не
простое, у него должен быть делитель, меньше или равный
@math{\sqrt{n}}.@footnote{Если @math{d} --- делитель @math{n}, то
@math{n / d} тоже. Но @math{d} и @math{n /
d} не могут оба быть больше @math{\sqrt{n}}.} Это означает, что
алгоритм может проверять делители только от 1 до @math{\sqrt{n}}.
Следовательно, число шагов, которые требуются, чтобы определить, что
@math{n} простое, будет иметь порядок роста @math{\Theta(\sqrt{n})}.

@comment @subsubheading The Fermat test
@subsubheading Тест Ферма
Тест на простоту с порядком роста @math{\Theta(\log n)} основан на
утверждении из теории чисел, известном как Малая теорема
Ферма.@footnote{Пьер де Ферма (1601-1665) считается основателем
современной теории чисел. Он доказал множество важных теорем, однако,
как правило, он объявлял только результаты, не публикуя своих
доказательств. Малая теорема Ферма была сформулирована в письме, которое
он написал в 1640-м году. Первое опубликованное доказательство было
даноЭйлером в 1736 г. (более раннее, идентичное доказательство было
найдено в неопубликованных рукописях Лейбница). Самый знаменитый
результат Ферма, известный как Большая теорема Ферма, был записан в
1637 году в его экземпляре книги @cite{Арифметика} (греческого
математика третьего века Диофанта) с пометкой <<я нашел подлинно
удивительное доказательство, но эти поля слишком малы, чтобы вместить
его>>. Доказательство Большой теоремы Ферма стало одним из самых
известных вопросов теории чисел. Полное решение было найдено в 1995
году Эндрю Уайлсом из Принстонского университета.}

@quotation
@strong{Малая теорема Ферма:}
Если @math{n} --- простое число, а @math{a} --- произвольное целое число
меньше, чем @math{n}, то @math{a}, возведенное в @math{n}-ю степень,
равно @math{a} по модулю @math{n}.
@end quotation

@noindent
(Говорят, что два числа (congruent modulo @math{n}), если они дают
одинаковый остаток при делении на @math{n}. Остаток от деления числа
@math{a} на @math{n} называется также (remainder of @math{a} modulo
@math{n}) или просто @emph{@math{a} по модулю @math{n}}.)

Если @math{n} не является простым, то, вообще говоря, большинство чисел
@math{a < n} не будут удовлетворять этому условию. Это приводит к
следующему алгоритму проверки на простоту: имея число @math{n},
случайным образом выбрать число @math{a < n} и вычислить остаток от
@math{a^n} по модулю @math{n}. Если этот остаток не равен @math{a}, то
@math{n} определенно не является простым. Если он равен @math{a}, то мы
имеем хорошие шансы, что @math{n} простое. Тогда нужно взять еще одно
случайное @math{a} и проверить его тем же способом. Если и оно
удовлетворяет уравнению, мы можем быть еще более уверены, что @math{n}
простое. Испытывая все большее количество @math{a}, мы можем увеличивать
нашу уверенность в результате. Этот алгоритм называется тестом Ферма.

Для реализации теста Ферма нам нужна процедура, которая вычисляет
степень числа по модулю другого числа:

@lisp
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder
          (square (expmod base (/ exp 2) m))
          m))
        (else
         (remainder
          (* base (expmod base (- exp 1) m))
          m))))
@end lisp

@noindent
Эта процедура очень похожа на @code{fast-expt} из
раздела @ref{1.2.4}. Она использует последовательное
возведение в квадрат, так что число шагов логарифмически растет с
увеличением степени.@footnote{Шаги редукции для случаев, когда степень
больше 1, основаны на том, что для любых целых чисел @math{x},
@math{y} и @math{m} мы можем найти остаток от деления произведения
@math{x} и @math{y} на @math{m} путем отдельного вычисления остатков
@math{x} по модулю @math{m}, @math{y} по модулю @math{m}, перемножения
их, и взятия остатка по модулю @math{m} от результата. Например, в
случае, когда @math{e} четно, мы можем вычислить остаток
@math{b^{e / 2}} по модулю @math{m}, возвести его в квадрат и взять
остаток по модулю @math{m}. Такой метод полезен потому, что с его
помощью мы можем производить вычисления, не используя чисел, намного
больших, чем @math{m}. (Сравните с @ref{Упражнение 1.25}.)}

Тест Ферма производится путем случайного выбора числа @math{a} между
1 и @math{n - 1} включительно и проверки, равен ли @math{a} остаток по
модулю @math{n} от @math{n}-ой степени @math{a}. Случайное число
@math{a} выбирается с помощью процедуры , про которую мы предполагаем,
что она встроена в Scheme в качестве элементарной процедуры.
@code{random} возвращает неотрицательное число, меньшее, чем ее целый
аргумент. Следовательно, чтобы получить случайное число между 1 и
@math{n - 1}, мы вызываем @code{random} с аргументом @math{n - 1} и
добавляем к результату 1:

@lisp
(define (fermat-test n)
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))
@end lisp

@noindent
Следующая процедура прогоняет тест заданное число раз, как указано ее
параметром. Ее значение истинно, если тест всегда проходит, и ложно в
противном случае.

@lisp
(define (fast-prime? n times)
  (cond ((= times 0) true)
        ((fermat-test n) (fast-prime? n (- times 1)))
        (else false)))
@end lisp

@comment @subsubheading Probabilistic methods
@subsubheading Вероятностные методы

Тест Ферма отличается по своему характеру от большинства известных
алгоритмов, где вычисляется результат, истинность которого
гарантирована. Здесь полученный результат верен лишь с какой-то
вероятностью. Более точно, если @math{n} не проходит тест Ферма, мы
можем точно сказать, что оно не простое. Но то, что @math{n} проходит
тест, хотя и является очень сильным показателем, все же не гарантирует,
что @math{n} простое. Нам хотелось бы сказать, что для любого числа
@math{n}, если мы проведем тест достаточное количество раз и @math{n}
каждый раз его пройдет, то вероятность ошибки в нашем тесте на простоту
может быть сделана настолько малой, насколько мы того пожелаем.

К сожалению, это утверждение неверно. Существуют числа, которые
<<обманывают>> тест Ферма: числа, которые не являются простыми и тем не
менее обладают свойством, что для всех целых чисел @math{a < n}
@math{a^n} равно @math{a} по модулю @math{n}. Такие числа очень редки,
так что на практике тест Ферма вполне надежен.@footnote{Числа,
<<обманывающие>> тест Ферма, называются (@newterm{Carmichael numbers}),
и про них
почти ничего неизвестно, кроме того, что они очень редки. Существует 255
чисел Кармайкла, меньших 100 000 000. Несколько первых --- 561, 1105,
1729, 2465, 2821 и 6601. При проверке на простоту больших чисел,
выбранных случайным образом, шанс наткнуться на число, <<обманывающее>>
тест Ферма, меньше, чем шанс, что космическое излучение заставит
компьютер сделать ошибку при вычислении <<правильного>> алгоритма. То,
что по первой из этих причин алгоритм считается неадекватным, а по
второй нет, показывает разницу между математикой и техникой.}

Существуют варианты теста Ферма, которые обмануть невозможно. В таких
тестах, подобно методу Ферма, проверка числа @math{n} на простоту
ведется путем выбора случайного числа @math{a < n} и проверки некоторого
условия, зависящего от @math{n} и @math{a}. (Пример такого теста см. в
упражнении @ref{Упражнение 1.28}.) С другой стороны, в отличие от
теста Ферма, можно доказать, что для любого @math{n} условие не
выполняется для большинства чисел @math{a < n}, если @math{n} не
простое. Таким образом, если @math{n} проходит тест для какого-то
случайного @math{a}, шансы, что @math{n} простое, уже больше половины.
Если @math{n} проходит тест для двух случайных @math{a}, шансы, что
@math{n} простое, больше, чем 3 из 4. Проводя тест с большим
количеством случайных чисел, мы можем сделать вероятность ошибки сколь
угодно малой.

Существование тестов, для которых можно доказать, что вероятность ошибки
можно сделать сколь угодно малой, вызвало большой интерес к алгоритмам
такого типа. Их стали называть (@newterm{probabilistic alorithms}).
В этой области
ведутся активные исследования, и вероятностные алгоритмы удалось с
успехом применить во многих областях@footnote{Одно из наиболее
впечатляющих применений вероятностные алгоритмы получили в области
криптографии. Хотя в настоящее время вычислительных ресурсов
недостаточно, чтобы разложить на множители произвольное число из 200
цифр, с помощью теста Ферма проверить, является ли оно простым, можно
за несколько секунд. Этот факт служит основой предложенного в @ref{Rivest,
Shamir, and Adleman (1977)} метода построения шифров, которые
<<невозможно>> взломать. Полученный алгоритм RSA (@newterm{RSA algorithm})
стал широко используемым методом повышения секретности электронных
средств связи. В результате этого и других связанных событий
исследование простых чисел, которое раньше считалось образцом <<чистой>>
математики, изучаемым исключительно ради самого себя, теперь получило
важные практические приложения в таких областях, как криптография,
электронная передача денежных сумм и хранение информации.}.

@quotation
@strong{@anchor{Упражнение 1.21}Упражнение 1.21:} С помощью процедуры
@code{smallest-divisor} найдите наименьший делитель следующих чисел: 199,
1999, 19999.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.22}Упражнение 1.22:} Бо́льшая часть реализаций
Лиспа содержат элементарную
процедуру @code{runtime}, которая возвращает целое число, показывающее,
как долго работала система (например, в миллисекундах). Следующая
процедура @code{timed-prime-test}, будучи вызвана с целым числом
@math{n}, печатает @math{n} и проверяет, простое ли оно. Если @math{n}
простое, процедура печатает три звездочки и количество времени,
затраченное на проверку.

@lisp
(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))
(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime) start-time))))
(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
@end lisp

Используя эту процедуру, напишите процедуру @code{search-for-primes},
которая проверяет на простоту все нечетные числа в заданном диапазоне.
С помощью этой процедуры найдите наименьшие три простых числа после
1000; после 10 000; после 100 000; после 1 000 000. Посмотрите,
сколько времени затрачивается на каждое простое число. Поскольку
алгоритм проверки имеет порядок роста @math{\Theta (\sqrt{n})}, Вам
следовало бы ожидать, что проверка на простоту чисел, близких к
10 000, занимает в @math{\sqrt{10}} раз больше времени, чем для чисел,
близких к 1000. Подтверждают ли это Ваши замеры времени? Хорошо ли
поддерживают предсказание @math{\sqrt{n}} данные для 100 000 и
1 000 000? Совместим ли Ваш результат с предположением, что программы
на Вашей машине затрачивают на выполнение задач время, пропорциональное
числу шагов?
@end quotation

@quotation
@strong{@anchor{Упражнение 1.23}Упражнение 1.23:} @code{smallest-divisor}
Процедура в начале этого раздела проводит множество лишних
проверок: после того, как она проверяет, делится ли число на 2, нет
никакого смысла проверять делимость на другие четные числа. Таким
образом, вместо последовательности 2, 3, 4, 5, 6 @dots{}, используемой
для @code{test-divisor}, было бы лучше использовать 2, 3, 5, 7, 9
@dots{}. Чтобы реализовать такое улучшение, напишите процедуру
@code{next}, которая имеет результатом 3, если получает 2 как
аргумент, а иначе возвращает свой аргумент плюс 2. Используйте
@code{(next test-divisor)} вместо @code{(+ test-divisor 1)} в
@code{smallest-divisor}. Используя процедуру @code{timed-prime-test} с
модифицированной версией @code{smallest-divisor}, запустите тест для
каждого из 12 простых чисел, найденных в @ref{Упражнение 1.22}.
Поскольку эта модификация снижает
количество шагов проверки вдвое, Вы должны ожидать двукратного ускорения
проверки. Подтверждаются ли эти ожидания? Если нет, то каково
наблюдаемое соотношение скоростей двух алгоритмов, и как Вы объясните
то, что оно отличается от 2?
@end quotation

@quotation
@strong{@anchor{Упражнение 1.24}Упражнение 1.24:} Модифицируйте процедуру
@code{timed-prime-test} из упражнения @ref{Упражнение 1.22} так, чтобы
она использовала
@code{fast-prime?} (метод Ферма) и проверьте каждое из 12 простых
чисел, найденных в этом упражнении. Исходя из того, что у теста Ферма
порядок роста @math{\Theta (\log n)}, то какого соотношения времени Вы
бы ожидали между проверкой на простоту поблизости от 1 000 000 и
поблизости от 1000? Подтверждают ли это Ваши данные? Можете ли Вы
объяснить наблюдаемое несоответствие, если оно есть?
@end quotation

@quotation
@strong{@anchor{Упражнение 1.25}Упражнение 1.25:} Лиза П. Хакер жалуется, что при написании @code{expmod} мы
делаем много лишней работы. В конце концов, говорит она, раз мы уже
знаем, как вычислять степени, можно просто написать

@lisp
(define (expmod base exp m)
  (remainder (fast-expt base exp) m))
@end lisp

Права ли она? Стала бы эта процедура столь же хорошо работать при
проверке простых чисел? Объясните.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.26}Упражнение 1.26:} У Хьюго Дума большие трудности в @ref{Упражнение 1.24}. Процедура @code{fast-prime?} у него
работает медленнее, чем @code{prime?}. Хьюго просит помощи у своей
знакомой Евы Лу Атор. Вместе изучая код Хьюго, они обнаруживают, что тот
переписал процедуру @code{expmod} с явным использованием умножения
вместо того, чтобы вызывать @code{square}:

@lisp
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (* (expmod base (/ exp 2) m)
                       (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base
                       (expmod base (- exp 1) m))
                    m))))
@end lisp

Хьюго говорит: <<Я не вижу здесь никакой разницы>>. <<Зато я вижу, ---
отвечает Ева. --- Переписав процедуру таким образом, ты превратил
процесс порядка @math{\Theta(\log n)} в процесс порядка
@math{\Theta(n)}>>. Объясните.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.27}Упражнение 1.27:} Покажите, что числа Кармайкла, перечисленные в сноске
@ref{Сноска 47}, действительно <<обманывают>> тест Ферма: напишите
процедуру, которая берет целое число @math{n} и проверяет, правда ли
@math{a^n} равняется @math{a} по модулю @math{n} для всех
@math{a < n}, и проверьте эту процедуру на этих числах Кармайкла.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.28}Упражнение 1.28:} Один из вариантов
теста Ферма, который невозможно обмануть, называется
@newterm{Miller-Rabin test} (@ref{Miller 1976}; @ref{Rabin 1980}). Он основан
наальтернативной формулировке Малой теоремы Ферма, которая состоит в
том, что если @math{n} --- простое число, а @math{a} --- произвольное
положительное целое число, меньшее @math{n}, то @math{a} в
@math{n - 1}-ой степени равняется 1 по модулю @math{n}. Проверяя
простоту числа @math{n} методом Миллера--Рабина, мы берем случайное
число @math{a < n} и возводим его в @math{(n 
-1)}-ю степень по модулю @math{n} с помощью процедуры @code{expmod}.
Однако когда в процедуре @code{expmod} мы проводим возведение в
квадрат, мы проверяем, не нашли ли мы <<нетривиальный квадратный корень
из 1 по модулю @math{n}>>, то есть число, не равное 1 или @math{n - 1},
квадрат которого по модулю @math{n} равен 1. Можно доказать, что если
такой нетривиальный квадратный корень из 1 существует, то @math{n} не
простое число. Можно, кроме того, доказать, что если @math{n} ---
нечетное число, не являющееся простым, то по крайней мере для половины
чисел @math{a < n} вычисление @math{a^{n-1}} с помощью такой процедуры
обнаружит нетривиальный квадратный корень из 1 по модулю @math{n} (вот
почему тест Миллера--Рабина невозможно обмануть). Модифицируйте
процедуру @code{expmod} так, чтобы она сигнализировала обнаружение
нетривиального квадратного корня из 1, и используйте ее для реализации
теста Миллера--Рабина с помощью процедуры, аналогичной
@code{fermat-test}. Проверьте свою процедуру на нескольких известных Вам
простых и составных числах. Подсказка: удобный способ заставить
@code{expmod} подавать особый сигнал --- заставить ее возвращать 0.

@end quotation

@sp 0.5
@comment @section Formulating Abstractions@* with Higher-Order Procedures
@section Формулирование абстракций с помощью процедур высших порядков
@node	1.3,  , 1.2, Chapter 1

Мы видели, что процедуры, в сущности, являются абстракциями, которые
описывают составные операции над числами безотносительно к конкретным
числам. Например, когда мы определяем

@lisp
(define (cube x) (* x x x))
@end lisp

@noindent
мы говорим не о кубе какого-то конкретного числа, а о способе
получить куб любого числа. Разумеется, мы могли бы обойтись без
определения этой процедуры, каждый раз писать выражения вроде

@lisp
(* 3 3 3)
(* x x x)
(* y y y)
@end lisp

@noindent
и никогда явно не упоминать понятие куба. Это поставило бы нас перед
серьезным затруднением и заставило бы работать только в терминах тех
операций, которые оказались примитивами языка (в данном случае, в
терминах умножения), а не в терминах операций более высокого уровня.
Наши программы были бы способны вычислять кубы, однако в нашем языке не
было бы возможности выразить идею возведения в куб. Одна из тех вещей,
которых мы должны требовать от мощного языка программирования --- это
возможность строить абстракции путем присвоения имен общим схемам, а
затем прямо работать с этими абстракциями. Процедуры дают нам такую
возможность. Вот почему все языки программирования, кроме самых
примитивных, обладают механизмами определения процедур.

Но даже при обработке численных данных наши возможности создавать
абстракции окажутся сильно ограниченными, если мы сможем определять
только процедуры, параметры которых должны быть числами. Часто одна и
та же схема программы используется с различными процедурами. Для того
чтобы выразить эти схемы как понятия, нам нужно строить процедуры,
которые принимают другие процедуры как аргументы либо возвращают их как
значения. Процедура, манипулирующая другими процедурами, называется
(higher-order procedure). В этом разделе показывается, как процедуры
высших порядков могут служить в качестве мощного механизма абстракции,
резко повышая выразительную силу нашего языка.

@menu
* 1-3-1::            Процедуры в качестве аргументов
* 1-3-2::            Построение процедур с помощью @code{lambda}
* 1-3-3::            Процедуры как обобщенные методы
* 1-3-4::            Процедуры как возвращаемые значения
@end menu

@comment @subsection Procedures as Arguments
@subsection Процедуры в качестве аргументов
@node	1.3.1, 1.3.2, 1.3, 1.3

Рассмотрим следующие три процедуры. Первая из них вычисляет сумму целых
чисел от @code{a} до @code{b}:

@lisp
(define (sum-integers a b)
  (if (> a b)
      0
      (+ a (sum-integers (+ a 1) b))))
@end lisp

@noindent
Вторая вычисляет сумму кубов целых чисел в заданном диапазоне:

@lisp
(define (sum-cubes a b)
  (if (> a b)
      0
      (+ (cube a)
         (sum-cubes (+ a 1) b))))
@end lisp

@noindent
Третья вычисляет сумму последовательности термов в ряде
@ifinfo

@example
  1       1       1
----- + ----- + ------ + ...
1 * 3   5 * 7   9 * 11
@end example

@end ifinfo
@tex
$$ {1\over1\cdot 3} +  {1\over5\cdot 7} + {1\over9\cdot 11} + \dots, $$
@end tex
@noindent
который (очень медленно) сходится к @math{\pi / 8}:@footnote{Этим рядом,
который обычно записывают в эквивалентной форме
@math{{pi\over4} = 1 - {1\over3} + {1\over5} - {1\over7} + \dots}, мы
обязаны Лейбницу. В разделе @ref{3.5.3}
мы увидим, как использовать его как основу для некоторых изощренных
вычислительных трюков.}

@lisp
(define (pi-sum a b)
  (if (> a b)
      0
      (+ (/ 1.0 (* a (+ a 2)))
         (pi-sum (+ a 4) b))))
@end lisp

@noindent
Ясно, что за этими процедурами стоит одна общая схема. Большей частью
они идентичны и различаются только именем процедуры, функцией, которая
вычисляет терм, подлежащий добавлению, и функцией, вычисляющей
следующее значение @code{a}. Все эти процедуры можно породить, заполнив
дырки в одном шаблоне:

@lisp
(define (@math{\langle}@var{имя}@math{\rangle} a b)
  (if (> a b)
      0
      (+ (@math{\langle}@var{терм}@math{\rangle} a)
         (@math{\langle}@var{имя}@math{\rangle} (@math{\langle}@var{следующий}@math{\rangle} a) b))))
@end lisp

@noindent
Присутствие такого общего шаблона является веским доводом в пользу
того, что здесь скрыта полезная абстракция, которую только надо вытащить
на поверхность. Действительно, математики давно выделили абстракцию
(summation of a series) и изобрели <<сигма-запись>>, например
@ifinfo

@example
  b
 ---
 >    f(n) = f(a) + ... + f(b)
 ---
 n=a
@end example

@end ifinfo
@tex
$$ \sum\limits_{n=a}^b f(n) = f(a) + \dots + f(b), $$
@end tex
@noindent
чтобы выразить это
понятие. Сила сигма-записи состоит в том, что она позволяет математикам
работать с самим понятием суммы, а не просто с конкретными суммами ---
например, формулировать общие утверждения о суммах, независимые от
конкретных суммируемых последовательностей.

Подобным образом, мы как проектировщики программ хотели бы, чтобы наш
язык был достаточно мощным и позволял написать процедуру, которая
выражала бы само понятие суммы, а не только процедуры, вычисляющие
конкретные суммы. В нашем процедурном языке мы можем без труда это
сделать, взяв приведенный выше шаблон и преобразовав <<дырки>> в
формальные параметры:

@lisp
(define (sum term a next b)
  (if (> a b)
      0
      (+ (term a)
         (sum term (next a) next b))))
@end lisp

@noindent
Заметьте, что @code{sum} принимает в качестве аргументов как нижнюю и
верхнюю границы @code{a} и @code{b}, так и процедуры @code{term} и
@code{next}. @code{Sum} можно использовать так, как мы использовали бы
любую другую процедуру. Например, с ее помощью (вместе с процедурой
@code{inc}, которая увеличивает свой аргумент на 1), мы можем определить
@code{sum-cubes}:

@lisp
(define (inc n) (+ n 1))
(define (sum-cubes a b)
  (sum cube a inc b))
@end lisp

@noindent
Воспользовавшись этим определением, мы можем вычислить сумму кубов чисел
от 1 до 10:

@lisp
(sum-cubes 1 10)
@i{3025}
@end lisp

@noindent
С помощью процедуры идентичности (которая просто возвращает свой
аргумент) для вычисления терма, мы можем определить @code{sum-integers}
через @code{sum}:

@lisp
(define (identity x) x)
(define (sum-integers a b)
  (sum identity a inc b))
@end lisp

@noindent
Теперь можно сложить целые числа от 1 до 10:

@lisp
(sum-integers 1 10)
@i{55}
@end lisp

@noindent
Таким же образом определяется @code{pi-sum}:@footnote{Обратите внимание,
что мы использовали блочную структуру
(раздел @ref{1.1.8}), чтобы
спрятать определения @code{pi-next} и @code{pi-term} внутри
@code{pi-sum}, поскольку вряд ли эти процедуры понадобятся зачем-либо
еще. В разделе @ref{1.3.2} мы совсем от них избавимся.}

@lisp
(define (pi-sum a b)
  (define (pi-term x)
    (/ 1.0 (* x (+ x 2))))
  (define (pi-next x)
    (+ x 4))
  (sum pi-term a pi-next b))
@end lisp

@noindent
С помощью этих процедур мы можем вычислить приближение к @math{\pi}:

@lisp
(* 8 (pi-sum 1 1000))
@i{3.139592655589783}
@end lisp

@noindent
Теперь, когда у нас есть @code{sum}, ее можно использовать в качестве
строительного блока при формулировании других понятий. Например,
определенный интеграл функции @math{f} между пределами @math{a} и
@math{b} можно численно оценить с помощью формулы
@ifinfo

@example
/b     /  /     dx \    /          dx \    /           dx \      \
|  f = | f| a + -- | + f| a + dx + -- | + f| a + 2dx + -- | + ...| dx
/a     \  \     2  /    \          2  /    \           2  /      /
@end example

@end ifinfo
@tex
$${\int_a^b \!\!\! f} = {\left[\;f\! \left(a + {dx \over 2}\right)
		+ f\! \left(a + dx + {dx \over 2}\right)
		+ f\! \left(a + 2dx + {dx \over 2}\right) + \,\dots \;\right]\! dx} $$
@end tex
@noindent
для малых значений @math{dx}. Мы можем прямо выразить это в виде процедуры:

@lisp
(define (integral f a b dx)
  (define (add-dx x)
    (+ x dx))
  (* (sum f (+ a (/ dx 2.0)) add-dx b)
     dx))

(integral cube 0 1 0.01)
@i{.24998750000000042}

(integral cube 0 1 0.001)
@i{.249999875000001}
@end lisp

@noindent
(Точное значение интеграла @code{cube} от 0 до 1 равно 1/4.)

@quotation
@strong{@anchor{Упражнение 1.29}Упражнение 1.29:} Правило Симпсона --- более точный метод численного
интегрирования, чем представленный выше. С помощью правила Симпсона
интеграл функции @math{f} между @math{a} и @math{b} приближенно
вычисляется в виде
@ifinfo

@example
h
- (y_0 + 4y_1 + 2y_2 + 4y_3 + 2y_4 + ... + 2y_(n-2) + 4y_(n-1) + y_n)
3
@end example

@end ifinfo
@tex
$$ {h\over 3}(y_0 + 4y_1 + 2y_2 + 4y_3 + 2y_4 + \dots + 2y_{n-2} + 4y_{n-1} + y_n), $$
@end tex
@noindent
где @math{h = (b - a) / n}, для какого-то четного целого числа
@math{n}, а @math{y_k = f(a + kh)}.
(Увеличение @math{n} повышает точность приближенного вычисления.)
Определите процедуру, которая принимает в качестве аргументов @math{f},
@math{a}, @math{b} и @math{n}, и возвращает значение интеграла,
вычисленное по правилу Симпсона. С помощью этой процедуры
проинтегрируйте @code{cube} между 0 и 1 (с @math{n = 100} и @math{n =
1000}) и сравните результаты с процедурой @code{integral}, приведенной
выше.
@end quotation

@quotation
@strong{@anchor{Exercise 1.30}Exercise 1.30:} Процедура @code{sum}
порождает линейную рекурсию. Ее можно переписать
так, чтобы суммирование выполнялось итеративно. Покажите, как сделать
это, заполнив пропущенные выражения в следующем определении:

@lisp
(define (sum term a next b)
  (define (iter a result)
    (if @math{\langle}??@math{\rangle}
        @math{\langle}??@math{\rangle}
        (iter @math{\langle}??@math{\rangle} @math{\langle}??@math{\rangle})))
  (iter @math{\langle}??@math{\rangle} @math{\langle}??@math{\rangle}))
@end lisp
@end quotation

@quotation
@strong{@anchor{Упражнение 1.31}Упражнение 1.31:} @enumerate a.

@item
Процедура @code{sum} --- всего лишь простейшая из обширного множества
подобных абстракций, которые можно выразить через процедуры высших
порядков.@footnote{Смысл
упражнений @ref{Упражнение 1.31}--@ref{Упражнение 1.33} состоит в
том, чтобы продемонстрировать выразительную мощь, получаемую, когда с
помощью подходящей абстракции обобщается множество операций, казалось
бы, не связанных между собой. Однако, хотя накопление и фильтрация ---
изящные приемы, при их использовании руки у нас пока что несколько
связаны, поскольку пока что у нас нет структур данных, которые дают
подходящие к этим абстракциям средства комбинирования. В
разделе @ref{2.23} мы вернемся к этим приемам и покажем,
как использовать (@newterm{sequences}) в
качестве интерфейсов для комбинирования фильтров и накопителей, так что
получаются еще более мощные абстракции. Мы увидим, как эти методы сами
по себе становятся мощным и изящным подходом к проектированию
программ.}. Напишите аналогичную процедуру под названием , которая
вычисляет произведение значений функции в точках на указанном
интервале. Покажите, как с помощью этой процедуры определить
@code{factorial}. Кроме того, при помощи @code{product} вычислите
приближенное значение @math{\pi} по формуле@footnote{Эту формулу открыл
английский математик семнадцатого века Джон Уоллис.}
@ifinfo

@example
pi   2 * 4 * 4 * 6 * 6 * 8 ...
-- = -------------------------
 4   3 * 3 * 5 * 5 * 7 * 7 ...
@end example

@end ifinfo
@tex
$$ {\pi\over 4} = {2\cdot 4\cdot 4\cdot 6\cdot 6\cdot 8\cdots\over
		   3\cdot 3\cdot 5\cdot 5\cdot 7\cdot 7\cdots}\,. $$
@end tex
@item
Если Ваша процедура @code{product} порождает рекурсивный процесс,
перепишите ее так, чтобы она порождала итеративный. Если она порождает
итеративный процесс, перепишите ее так, чтобы она порождала рекурсивный.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Упражнение 1.32}Упражнение 1.32:} @enumerate a.

@item
Покажите, что  и @code{product} (@ref{Упражнение 1.31})
являются частными случаями еще более общего понятия, называемого
@code{accumulation}, которое комбинирует множество термов с помощью
некоторой общей функции накопления:

@lisp
(accumulate combiner null-value term a next b)
@end lisp

@code{accumulate} принимает в качестве аргументов те же описания
термов и диапазона, что и @code{sum} с @code{product}, а еще
процедуру @code{combiner} (двух аргументов), которая указывает, как
нужно присоединить текущий терм к результату накопления предыдущих, и
@code{null-value}, базовое значение, которое нужно использовать, когда
термы закончатся. Напишите @code{accumulate} и покажите, как и
@code{sum}, и @code{product} можно определить в виде простых вызовов
@code{accumulate}.

@item
Если Ваша процедура @code{accumulate} порождает рекурсивный процесс,
перепишите ее так, чтобы она порождала итеративный. Если она порождает
итеративный процесс, перепишите ее так, чтобы она порождала рекурсивный.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Упражнение 1.33}Упражнение 1.33:}  Можно получить
еще более общую версию @code{accumulate}
(@ref{Упражнение 1.32}), если ввести понятие (filter) на
комбинируемые термы. То есть комбинировать только те термы, порожденные
из значений диапазона, которые удовлетворяют указанному условию.
Получающаяся абстракция @code{filtered-accumulate} получает те же
аргументы, что и @code{accumulate}, плюс дополнительный одноаргументный
предикат, который определяет фильтр. Запишите
@code{filtered-accumulate} в виде процедуры. Покажите, как с помощью
@code{filtered-accumulate} выразить следующее:

@item
сумму квадратов простых чисел в интервале от @code{a} до @code{b} (в
предположении, что процедура @code{prime?} уже написана);

@item
произведение всех положительных целых чисел меньше @math{n}, которые
просты по отношению к @math{n} (то есть всех таких положительных целых
чисел @math{i < n}, что @math{\textsc{НОД}(i,n) = 1}).

@end enumerate
@end quotation

@comment @subsection Constructing Procedures Using @code{lambda}
@subsection Построение процедур с помощью @code{lambda}
@node	1.3.2, 1.3.3, 1.3.1, 1.3

Когда в разделе @ref{1.3.1} мы использовали
@code{sum}, очень неудобно было определять тривиальные процедуры вроде
@code{pi-term} и @code{pi-next} только ради того, чтобы передать их как
аргументы в процедуры высшего порядка. Было бы проще вместо того, чтобы
вводить имена @code{pi-next} и @code{pi-term}, прямо определить
<<процедуру, которая возвращает свой аргумент плюс 4>> и <<процедуру,
которая вычисляет число, обратное произведению аргумента и аргумента
плюс 2>>. Это можно сделать, введя особую форму @code{lambda}, которая
создает процедуры. С использованием @code{lambda} мы можем записать
требуемое в таком виде:

@lisp
(lambda (x) (+ x 4))
@end lisp

@noindent
и

@lisp
(lambda (x) (/ 1.0 (* x (+ x 2))))
@end lisp

@noindent
Тогда нашу процедуру @code{pi-sum} можно выразить безо всяких
вспомогательных процедур:

@lisp
(define (pi-sum a b)
  (sum (lambda (x) (/ 1.0 (* x (+ x 2))))
       a
       (lambda (x) (+ x 4))
       b))
@end lisp

@noindent
Еще с помощью @code{lambda} мы можем записать процедуру
@code{integral}, не определяя вспомогательную процедуру @code{add-dx}:

@lisp
(define (integral f a b dx)
  (* (sum f
          (+ a (/ dx 2.0))
          (lambda (x) (+ x dx))
          b)
     dx))
@end lisp

@noindent
В общем случае, @code{lambda} используется для создания процедур точно
так же, как @code{define}, только никакого имени для процедуры не
указывается:

@lisp
(lambda (@math{\langle}@var{формальные-параметры}@math{\rangle}) @math{\langle}@var{тело}@math{\rangle})
@end lisp

@noindent
Получается столь же полноценная процедура, как и с помощью
@code{define}. Единственная разница состоит в том, что она не связана
ни с каким именем в окружении. На самом деле

@lisp
(define (plus4 x) (+ x 4))
@end lisp

@noindent
эквивалентно

@lisp
(define plus4 (lambda (x) (+ x 4)))
@end lisp

@noindent
Можно читать выражение @code{lambda} так:

@example
(lambda        (x)                  (+       x   4))
    |           |                    |       |   |
Процедура от аргумента x, которая складывает x и 4
@end example

@noindent
Подобно любому выражению, значением которого является процедура,
выражение с @code{lambda} можно использовать как оператор в
комбинации, например

@lisp
((lambda (x y z) (+ x y (square z)))
 1 2 3)
@i{12}
@end lisp

@noindent
или, в более общем случае, в любом контексте, где обычно используется
имя процедуры.@footnote{Было бы более понятно и менее страшно для
изучающих Лисп, если бы здесь использовалось более ясное имя, чем
@code{lambda}, например @code{make-procedure}. Однако традиция уже
прочно укоренилась. Эта нотация заимствована из
@math{\lambda}-исчисления, формализма, изобретенного математическим
логиком Алонсо Чёрчем @ref{Church 1941}. Чёрч разработал
@math{\lambda}-исчисление, чтобы найти строгое основание для понятий
функции и применения функции. @math{\lambda}-исчисление стало основным
инструментом математических исследований по семантике языков
программирования.}

@comment @subsubheading Using @code{let} to create local variables
@subsubheading Создание локальных переменных с помощью @code{let}

Еще одно применение @code{lambda} состоит во введении локальных
переменных. Часто нам в процедуре бывают нужны локальные переменные
помимо тех, что связаны формальными параметрами. Допустим, например, что
нам надо вычислить функцию
@ifinfo

@example
f(x,y) = x(1 + xy)^2 + y(1 - y) + (1 + xy)(1 - y)
@end example

@end ifinfo
@tex
$$ f(x,y) = x(1 + xy)^2 + y(1 - y) + (1 + xy)(1 - y), $$
@end tex
@noindent
которую мы также могли бы выразить как
@ifinfo

@example
     a = 1 + xy
     b = 1 - y
f(x,y) = xa^2 + yb + ab
@end example

@end ifinfo
@tex
$$
\begin{array}{r@{{}={}}l}
  a 	  &  1 + xy, \\
  b 	  &  1 - y,  \\
  f(x,y)  &  xa^2 + yb + ab.
\end{array}
$$
@end tex
Когда мы пишем процедуру для вычисления @math{f}, хотелось
бы иметь как локальные переменные не только @math{x} и @math{y}, но и
имена для промежуточных результатов вроде @math{a} и @math{b}. Можно
сделать это с помощью вспомогательной процедуры, которая связывает
локальные переменные:

@lisp
(define (f x y)
  (define (f-helper a b)
    (+ (* x (square a))
       (* y b)
       (* a b)))
  (f-helper (+ 1 (* x y))
            (- 1 y)))
@end lisp

@noindent
Разумеется, безымянную процедуру для связывания локальных переменных мы
можем записать через @code{lambda}-выражение. При этом тело @code{f}
оказывается просто вызовом этой процедуры.

@lisp
(define (f x y)
  ((lambda (a b)
     (+ (* x (square a))
        (* y b)
        (* a b)))
   (+ 1 (* x y))
   (- 1 y)))
@end lisp

@noindent
Такая конструкция настолько полезна, что есть особая форма под названием
@code{let}, которая делает ее более удобной. С использованием @code{let}
процедуру @code{f} можно записать так:

@lisp
(define (f x y)
  (let ((a (+ 1 (* x y)))
        (b (- 1 y)))
    (+ (* x (square a))
       (* y b)
       (* a b))))
@end lisp

@noindent
Общая форма выражения с @code{let} такова:

@lisp
(let ((@math{\langle}@var{пер}@math{_{\mono{1}}\rangle} @math{\langle}@var{выр}@math{_{\mono{1}}\rangle})
      (@math{\langle}@var{пер}@math{_{\mono{2}}\rangle} @math{\langle}@var{выр}@math{_{\mono{2}}\rangle})
      @dots{}
      (@math{\langle}@var{пер}@math{_{\monoit{n}}\rangle} @math{\langle}@var{выр}@math{_{\monoit{n}}\rangle}))
   @math{\langle}@var{тело}@math{\rangle})
@end lisp

@noindent
Это можно понимать как

@lisp
@w{Пусть} @math{\langle}@var{пер}@math{_{\mono{1}}\rangle} @w{имеет значение} @math{\langle}@var{выр}@math{_{\mono{1}}\rangle} @w{и}
    @math{\langle}@var{пер}@math{_{\mono{2}}\rangle} @w{имеет значение} @math{\langle}@var{выр}@math{_{\mono{2}}\rangle} @w{и}
    @dots{}
    @math{\langle}@var{пер}@math{_{\monoit{n}}\rangle} @w{имеет значение} @math{\langle}@var{выр}@math{_{\monoit{n}}\rangle}
@w{в}  @math{\langle}@var{теле}@math{\rangle}
@end lisp

@noindent
Первая часть @code{let}-выражения представляет собой список пар вида
имя--значение. Когда @code{let} вычисляется, каждое имя связывается со
значением соответствующего выражения. Затем вычисляется тело @code{let},
причем эти имена связаны как локальные переменные. Происходит это так:
выражение @code{let} интерпретируется как альтернативная форма для

@lisp
((lambda (@math{\langle}@var{пер}@math{_{\mono{1}}\rangle} @dots{} @math{\langle}@var{пер}@math{_{\monoit{n}}\rangle})
    @math{\langle}@var{тело}@math{\rangle})
 @math{\langle}@var{выр}@math{_{\mono{1}}\rangle}
 @dots{}
 @math{\langle}@var{выр}@math{_{\monoit{n}}\rangle})
@end lisp

@noindent
От интерпретатора не требуется никакого нового механизма связывания
переменных. Выражение с @code{let} --- это всего лишь синтаксический
сахар для вызова @code{lambda}.

Из этой эквивалентности мы видим, что область определения переменной,
введенной в @code{let}-выражении --- тело @code{let}. Отсюда следует,
что:


@itemize @bullet

@item
@code{let} позволяет связывать переменные сколь угодно близко к тому
месту, где они используются. Например, если значение @code{x} равно 5,
значение выражения

@lisp
(+ (let ((x 3))
     (+ x (* x 10)))
   x)
@end lisp

@noindent
равно 38. Значение @code{x} в теле @code{let} равно 3, так что значение
@code{let}-выражения равно 33. С другой стороны, @code{x} как второй
аргумент к внешнему @code{+} по-прежнему равен 5.

@item
Значения переменных вычисляются за пределами @code{let}. Это
существенно, когда выражения, дающие значения локальным переменным,
зависят от переменных, которые имеют те же имена, что и сами локальные
переменные. Например, если значение @code{x} равно 2, выражение

@lisp
(let ((x 3)
      (y (+ x 2)))
  (* x y))
@end lisp

@noindent
будет иметь значение 12, поскольку внутри тела @code{let} @code{x} будет
равно 3, а @code{y} 4 (что равняется внешнему @code{x} плюс 2).

@end itemize

@noindent
Иногда с тем же успехом, что и @code{let}, можно использовать
внутренние определения. Например, вышеописанную процедуру @code{f} мы
могли бы определить как

@lisp
(define (f x y)
  (define a (+ 1 (* x y)))
  (define b (- 1 y))
  (+ (* x (square a))
     (* y b)
     (* a b)))
@end lisp

@noindent
В таких ситуациях, однако, мы предпочитаем использовать @code{let}, а
@code{define} писать только при определении локальных
процедур.@footnote{Если мы хотим понимать внутренние определения
настолько, чтобы быть уверенными, что программа действительно
соответствует нашим намерениям, то нам требуется более сложная модель
процесса вычислений, чем приведенная в этой главе. Однако с внутренними
определениями процедур эти тонкости не возникают. К этому вопросу мы
вернемся в разделе @ref{4.1.6}, после того, как больше узнаем о вычислении.}

@quotation
@strong{@anchor{Упражнение 1.34}Упражнение 1.34:} Suppose we define the procedure

@lisp
(define (f g) (g 2))
@end lisp

Тогда мы имеем

@lisp
(f square)
@i{4}
(f (lambda (z) (* z (+ z 1))))
@i{6}
@end lisp

Что случится, если мы (извращенно) попросим интерпретатор вычислить
комбинацию @code{(f f)}? Объясните.
@end quotation

@comment @subsection Procedures as General Methods
@subsection Процедуры как обобщенные методы
@node	1.3.3, 1.3.4, 1.3.2, 1.3

Мы ввели составные процедуры в разделе @ref{1.1.4} в качестве механизма для
абстракции схем числовых операций, так, чтобы они были независимы от
конкретных используемых чисел. С процедурами высших порядков, такими,
как процедура @code{integral} из раздела @ref{1.3.1}, мы начали исследовать
более мощный тип абстракции: процедуры, которые используются для
выражения обобщенных методов вычисления, независимо от конкретных
используемых функций. В этом разделе мы рассмотрим два более подробных
примера --- общие методы нахождения нулей и неподвижных точек функций,
--- и покажем, как эти методы могут быть прямо выражены в виде
процедур.

@comment @subsubheading Finding roots of equations by the half-interval method
@subsubheading Нахождение корней уравнений методом половинного деления

(@newterm{half-interval method}) --- это простой, но мощный способ нахождения
корней уравнения @math{f(x) = 0}, где @math{f} --- непрерывная функция.
Идея состоит в том, что если нам даны такие точки @math{a} и @math{b},
что @math{f(a) < 0 < f(b)}, то функция @math{f} должна иметь по крайней мере
один ноль на отрезке между @math{a} и @math{b}. Чтобы найти его, возьмем
@math{x}, равное среднему между @math{a} и @math{b}, и вычислим @math{f(x)}.
Если @math{f(x) > 0}, то @math{f} должна иметь ноль на отрезке между
@math{a} и @math{x}. Если @math{f(x) < 0}, то @math{f} должна иметь ноль на
отрезке между @math{x} и @math{b}.
Продолжая таким образом, мы сможем находить все более узкие интервалы,
на которых @math{f} должна иметь ноль. Когда мы дойдем до точки, где
этот интервал достаточно мал, процесс останавливается. Поскольку
интервал неопределенности уменьшается вдвое на каждом шаге процесса,
число требуемых шагов растет как @math{\Theta(\log(L / T))}, где
@math{L} есть длина исходного интервала, а @math{T} есть допуск ошибки
(то есть размер интервала, который мы считаем <<достаточно малым>>). Вот
процедура, которая реализует эту стратегию:

@lisp
(define (search f neg-point pos-point)
  (let ((midpoint (average neg-point pos-point)))
    (if (close-enough? neg-point pos-point)
        midpoint
        (let ((test-value (f midpoint)))
          (cond ((positive? test-value)
                 (search f neg-point midpoint))
                ((negative? test-value)
                 (search f midpoint pos-point))
                (else midpoint))))))
@end lisp

@noindent
Мы предполагаем, что вначале нам дается функция @math{f} и две
точки, в одной из которых значение функции отрицательно, в другой
положительно. Сначала мы вычисляем среднее между двумя краями интервала.
Затем мы проверяем, не является ли интервал уже достаточно малым, и
если да, сразу возвращаем среднюю точку как ответ. Если нет, мы
вычисляем значение @math{f} в средней точке. Если это значение
положительно, мы продолжаем процесс с интервалом от исходной
отрицательной точки до средней точки. Если значение в средней точке
отрицательно, мы продолжаем процесс с интервалом от средней точки до
исходной положительной точки. Наконец, существует возможность, что
значение в средней точке в точности равно 0, и тогда средняя точка и
есть тот корень, который мы ищем.

Чтобы проверить, достаточно ли близки концы интервала, мы можем взять
процедуру, подобную той, которая используется в разделе @ref{1.1.7} при
вычислении квадратных корней:@footnote{Мы использовали 0.001 как
достаточно <<малое>> число, чтобы указать допустимую ошибку вычисления.
Подходящий допуск в настоящих вычислениях зависит от решаемой задачи,
ограничений компьютера и алгоритма. Часто это весьма тонкий вопрос, в
котором требуется помощь специалиста по численному анализу или
волшебника какого-нибудь другого рода.}

@lisp
(define (close-enough? x y) (< (abs (- x y)) 0.001))
@end lisp

@noindent
Использовать процедуру @code{search} непосредственно ужасно неудобно,
поскольку случайно мы можем дать ей точки, в которых значения @math{f}
не имеют нужных знаков, и в этом случае мы получим неправильный ответ.
Вместо этого мы будем использовать @code{search} посредством следующей
процедуры, которая проверяет, который конец интервала имеет
положительное, а который отрицательное значение, и соответствующим
образом зовет @code{search}. Если на обоих концах интервала функция
имеет одинаковый знак, метод половинного деления использовать нельзя, и
тогда процедура сообщает об ошибке:@footnote{Этого можно добиться с
помощью процедуры @code{error}, которая в качестве аргументов принимает
несколько значений и печатает их как сообщение об ошибке.}

@lisp
(define (half-interval-method f a b)
  (let ((a-value (f a))
        (b-value (f b)))
    (cond ((and (negative? a-value) (positive? b-value))
           (search f a b))
          ((and (negative? b-value) (positive? a-value))
           (search f b a))
          (else
           (error "Values are not of opposite sign" a b)))))
@end lisp

@noindent
В следующем примере метод половинного деления используется, чтобы вычислить
@math{\pi} как корень уравнения @math{\sin x = 0}, лежащий между 2 и 4.

@lisp
(half-interval-method sin 2.0 4.0)
@i{3.14111328125}
@end lisp

@noindent
Во втором примере через метод половинного деления ищется корень
уравнения @math{x^3 - 2x - 3 = 0}, расположенный между 1 и 2:

@lisp
(half-interval-method (lambda (x) (- (* x x x) (* 2 x) 3))
                      1.0
                      2.0)
@i{1.89306640625}
@end lisp

@comment @subsubheading Finding fixed points of functions
@subsubheading Нахождение неподвижных точек функций

Число @math{x} называется (fixed point) функции @math{f}, если оно
удовлетворяет уравнению @math{f(x) =
x}. Для некоторых функций @math{f} можно найти неподвижную точку,
начав с какого-то значения и применяя @math{f} многократно:
@ifinfo

@example
f(x), f(f(x)), f(f(f(x))), ...
@end example

@end ifinfo
@tex
$$ f(x),\quad f(f(x)),\quad f(f(f(x))), \quad\dots, $$
@end tex
@noindent
пока значение не перестанет
сильно изменяться. С помощью этой идеи мы можем составить процедуру
@code{fixed-point}, которая в качестве аргументов принимает функцию и
начальное значение и производит приближение к неподвижной точке
функции. Мы многократно применяем функцию, пока не найдем два
последовательных значения, разница между которыми меньше некоторой
заданной чувствительности:

@lisp
(define tolerance 0.00001)
(define (fixed-point f first-guess)
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2))
       tolerance))
  (define (try guess)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))
@end lisp

@noindent
Например, с помощью этого метода мы можем приближенно вычислить
неподвижную точку функции косинус, начиная с 1 как стартового
приближения:@footnote{Попробуйте во время скучной лекции установить
калькулятор в режим радиан и нажимать кнопку @code{cos}, пока не
найдете неподвижную точку.}

@lisp
(fixed-point cos 1.0)
@i{.7390822985224023}
@end lisp

@noindent
Подобным образом можно найти решение уравнени
@math{y = \sin y + \cos y}:

@lisp
(fixed-point (lambda (y) (+ (sin y) (cos y)))
             1.0)
@i{1.2587315962971173}
@end lisp

@noindent
Процесс поиска неподвижной точки похож на процесс, с помощью которого мы
искали квадратный корень в разделе @ref{1.1.7}. И тот, и
другой основаны на идее последовательного улучшения приближений, пока
результат не удовлетворит какому-то критерию. На самом деле мы без труда
можем сформулироватьвычисление квадратного корня как поиск неподвижной
точки. Вычислить квадратный корень из произвольного числа @math{x}
означает найти такое @math{y}, что @math{y^2 = x}. Переведя это
уравнение в эквивалентную форму @math{y = x / y}, мы обнаруживаем, что
должны найти неподвижную точку функции@footnote{@math{\mapsto}
(произносится <<отображается в>>) --- это математический способ написать
@code{lambda}. @math{y \mapsto x / y} означает
@code{(lambda (y) (/ x y))}, то есть функцию, значение которой в точке
@math{y} есть @math{x / y}.} @math{y \mapsto x / y}, и, следовательно,
мы можем попытаться вычислять квадратные корни так:

@lisp
(define (sqrt x)
  (fixed-point (lambda (y) (/ x y))
               1.0))
@end lisp

@noindent
К сожалению, этот поиск неподвижной точки не сходится. Рассмотрим
исходное значение @math{y_1}. Следующее значение равно
@math{y_2 = x / y_1}, а следующее за ним
@math{y_3 = x / y_2 = x / (x / y_1) = y_1}. В результате выходит
бесконечный цикл, в котором два значения @math{y_1} и @math{y_2}
повторяются снова и снова, прыгая вокруг правильного ответа.

Один из способов управлять такими прыжками состоит в том, чтобы
заставить значения изменяться не так сильно. Поскольку ответ всегда
находится между текущим значением @math{y} и @math{x
/ y}, мы можем взять новое значение, не настолько далекое от @math{y},
как @math{x / y}, взяв среднее между ними, так что следующее значение
будет не @math{x / y}, а @math{{1\over2}(y + x / y)}. Процесс
получения такой последовательности есть всего лишь процесс поиска
неподвижной точки @math{y \mapsto {1\over2}(y + x / y)}.

@lisp
(define (sqrt x)
  (fixed-point (lambda (y) (average y (/ x y)))
               1.0))
@end lisp

@noindent
(Заметим, что @math{y = {1\over2} (y + x / y)} всего лишь простая
трансформация уравнения @math{y = x / y}; чтобы ее получить, добавьте
@math{y} к обоим частям уравнения и поделите пополам.)

После такой модификации процедура поиска квадратного корня начинает
работать. В сущности, если мы рассмотрим определения, мы увидим, что
последовательность приближений к квадратному корню, порождаемая
здесь, в точности та же, что порождается нашей исходной процедурой
поиска квадратного корня из раздела @ref{1.1.7}. Этот подход с усреднением
последовательных приближений к решению, метод, который мы называем
(@newterm{average damping}), часто помогает достичь сходимости
при поисках неподвижной точки.

@quotation
@strong{@anchor{Упражнение 1.35}Упражнение 1.35:} Покажите, что золотое сечение
@math{\varphi} (раздел @ref{1.2.2}) есть неподвижная точка трансформации
@math{x \mapsto 1 + 1 / x}, и используйте этот факт для вычисления 
@math{\varphi} с помощью процедуры @code{fixed-point}.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.36}Упражнение 1.36:} Измените процедуру
@code{fixed-point} так, чтобы она
печатала последовательность приближений, которые порождает, с помощью
примитивов @code{newline} и @code{display} показанных в упражнении
@ref{Упражнение 1.22}. Затем найдите решение уравнения @math{x^x = 1000}
путем поиска неподвижной точки @math{x \mapsto \log(1000) / \log(x)}.
(Используйте встроенную процедуру Scheme @code{log}
которая вычисляет натуральные логарифмы.)
Посчитайте, сколько шагов это занимает при использовании торможения
усреднением и без него. (Учтите, что нельзя начинать @code{fixed-point}
со значения 1, поскольку это вызовет деление на @math{\log(1) = 0}.)
@end quotation

@quotation
@strong{@anchor{Упражнение 1.37}Упражнение 1.37:} @enumerate a.

@item
Бесконечная дробь (@newterm{continued fraction}) есть выражение вида
@ifinfo

@example
           N_1
f = ---------------------
               N_2
    D_1 + ---------------
                   N_3
          D_2 + ---------
                D_3 + ...
@end example

@end ifinfo
@tex
$$ {f} = \cfrac{N_1}{D_1 + \cfrac{N_2}{D_2 + \cfrac{N_3}{D_3 + \dots}}}\,. $$
@end tex
В качестве примера можно показать, что расширение бесконечной цепной
дроби при всех @math{N_i} и @math{D_i}, равных 1, дает @math{1 / \phi},
где @math{\phi} --- золотое сечение (описанное в
разделе @ref{1.2.2}). Один из способов вычислить цепную
дробь состоит в том, чтобы после заданного количества термов оборвать
вычисление. Такой обрыв --- так называемая (@newterm{@i{k}-term finite continued fraction})
из @math{k} элементов, --- имеет вид
@ifinfo

@example
       N_1
-----------------
          N_2
D_1 + -----------
      ...    N_K
          + -----
             D_K
@end example

@end ifinfo
@tex
$$ \cfrac{N_1}{D_1 + \cfrac{N_2}{\ddots + \cfrac{N_k}{D_k}}}\,. $$
@end tex
Предположим, что @code{n} и @code{d} --- процедуры одного аргумента
(номера элемента @math{i}), возвращающие @math{N_i} и @math{D_i}
элементов цепной дроби. Определите процедуру @code{cont-frac} так, чтобы
вычисление @code{(cont-frac n d k)} давало значение @math{k}-элементной
конечной цепной дроби. Проверьте свою процедуру, вычисляя приближения к
@math{1 / \varphi} с помощью

@lisp
(cont-frac (lambda (i) 1.0)
           (lambda (i) 1.0)
           k)
@end lisp

@noindent
для последовательных значений @code{k}. Насколько большим пришлось
сделать @code{k}, чтобы получить приближение, верное с точностью 4 цифры
после запятой?

@item
Если Ваша процедура @code{cont-frac} порождает рекурсивный процесс,
напишите вариант, который порождает итеративный процесс. Если она
порождает итеративный процесс, напишите вариант, порождающий рекурсивный
процесс.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Упражнение 1.38}Упражнение 1.38:} В 1737 году швейцарский
математик Леонард Эйлер опубликовал
статью @cite{De functionibus Continuis}, которая содержала расширение
цепной дроби для @math{e - 2}, где @math{e} --- основание натуральных
логарифмов. В этой дроби все @math{N_i} равны 1, а @math{D_i}
последовательно равны @math{1, 2, 1, 1, 4, 1, 1, 6,
1, 1, 8, \ldots}Напишите программу, использующую Вашу процедуру
@code{cont-frac} из упражнения @ref{Упражнение 1.37} для вычисления
@math{e} на основании формулы Эйлера.
@end quotation

@quotation
@strong{@anchor{Exercise 1.39}Exercise 1.39:} Представление тангенса
в виде цепной дроби было
опубликовано в 1770 году немецким математиком Й.Х. Ламбертом:
@ifinfo

@example
              x
tan x = ---------------
                x^2
        1 - -----------
                  x^2
            3 - -------
                5 - ...
@end example

@end ifinfo
@tex
$$ {\tan x} = \cfrac{x}{1 - \cfrac{x^2}{3 - \cfrac{x^2}{5 - \dots}}}\,, $$
@end tex
@noindent
где @math{x} дан в радианах. Определите процедуру @code{(tan-cf x k)},
которая вычисляет приближение к тангенсу на основе формулы Ламберта.
@code{K} указывает количество термов, которые требуется вычислить,
как в упражнении @ref{Упражнение 1.37}.

@end quotation

@comment @subsection Procedures as Returned Values
@subsection Процедуры как возвращаемые значения
@node	1.3.4,  , 1.3.3, 1.3

Предыдущие примеры показывают, что возможность передавать процедуры в
качестве аргументов значительно увеличивает выразительную силу нашего
языка программирования. Мы можем добиться еще большей выразительной
силы, создавая процедуры, возвращаемые значения которых сами являются
процедурами.

Эту идею можно проиллюстрировать примером с поиском неподвижной точки,
обсуждаемым в конце раздела @ref{1.3.3}. Мы сформулировали
новую версию процедуры вычисления квадратного корня как поиск
неподвижной точки, начав с наблюдения, что @math{\sqrt{x}} есть
неподвижная точка функции @math{y \mapsto x / y}. Затем мы использовали
торможение усреднением, чтобы заставить приближения сходиться.
Торможение усреднением само по себе является полезным приемом. А именно,
получив функцию @math{f}, мы возвращаем функцию, значение которой в
точке х есть среднее арифметическое между @math{x} и @math{f(x)}.

Идею торможения усреднением мы можем выразить при помощи следующей
процедуры:

@lisp
(define (average-damp f)
  (lambda (x) (average x (f x))))
@end lisp

@noindent
@code{average-damp} --- это процедура, принимающая в качестве аргумента
процедуру @code{f} и возвращающая в качестве значения процедуру
(полученную с помощью @code{lambda}), которая, будучи применена к
числу @code{x}, возвращает среднее между @code{x} и @code{(f x)}.
Например, применение @code{average-damp} к процедуре @code{square}
получает процедуру, значением которой для некоторого числа @math{x}
будет среднее между @math{x} и @math{x^2}. Применение этой процедуры к
числу 10 возвращает среднее между 10 и 100, то есть
55:@footnote{Заметьте, что здесь мы имеем комбинацию, оператор которой
сам по себе комбинация. В @ref{Упражнение 1.4} уже была
продемонстрирована возможность таких комбинаций, но то был всего лишь
игрушечный пример. Здесь мы начинаем чувствовать настоящую
потребность в выражениях такого рода --- когда нам нужно применить
процедуру, полученную в качестве значения из процедуры высшего
порядка.}

@lisp
((average-damp square) 10)
@i{55}
@end lisp

@noindent
Используя @code{average-damp}, мы можем переформулировать процедуру
вычисления квадратного корня следующим образом:

@lisp
(define (sqrt x)
  (fixed-point (average-damp (lambda (y) (/ x y)))
               1.0))
@end lisp

@noindent
Обратите внимание, как такая формулировка делает явными три идеи нашего
метода: поиск неподвижной точки, торможение усреднением и функцию
@math{y \mapsto x / y}. Полезно сравнить такую формулировку метода поиска
квадратного корня с исходной версией, представленной в разделе @ref{1.1.7}.
Вспомните, что обе процедуры выражают один и тот же процесс, и посмотрите,
насколько яснее становится его идея, когда мы выражаем процесс в
терминах этих абстракций. В общем случае существует много способов
сформулировать процесс в виде процедуры. Опытные программисты знают,
как выбрать те формулировки процедур, которые наиболее ясно выражают их
мысли, и где полезные элементы процесса показаны в виде отдельных
сущностей, которые можно использовать в других приложениях. Чтобы
привести простой пример такого нового использования, заметим, что
кубический корень @math{x} является неподвижной точкой функции
@math{y \mapsto x / y^2}, так что мы можем немедленно обобщить нашу
процедуру поиска квадратного корня так, чтобы она извлекала кубические
корни:@footnote{См. дальнейшее обобщение в @ref{Упражнение 1.45}}

@lisp
(define (cube-root x)
  (fixed-point (average-damp (lambda (y) (/ x (square y))))
               1.0))
@end lisp

@comment @subsubheading Newton's method
@subsubheading Метод Ньютона

Когда в разделе @ref{1.1.7} мы
впервые представили процедуру извлечения квадратного корня, мы
упомянули, что это лишь частный случай метода Ньютона (@newterm{Newton's method}).
Если @math{x \mapsto g(x)} есть дифференцируемая функция, то
решение уравнения @math{g(x) = 0} есть неподвижная точка функции
@math{x \mapsto f(x)}, где 

@ifinfo

@example
           g(x)
f(x) = x - -----
           Dg(x)
@end example

@end ifinfo
@tex
$$ {f(x) = x} - {g(x)\over Dg(x)} $$
@end tex
@noindent
а @math{Dg(x)} есть производная @math{g}, вычисленная в точке @math{x}.
Метод Ньютона состоит в том, чтобы применить описанный способ поиска
неподвижной точки и аппроксимировать решение уравнения путем поиска
неподвижной точки функции @math{f}.@footnote{Вводные курсы анализа
обычно описывают метод Ньютона через последовательность приближений
@math{x_{n+1} = x_n - g(x_n) / Dg(x_n)}. Наличие языка, на котором
мы можем говорить о процессах, а
также использование идеи неподвижных точек, упрощают описание этого
метода.} Для многих функций @math{g} при достаточно хорошем начальном
значении @math{x} метод Ньютона очень быстро приводит к решению
уравнения @math{g(x) = 0}.@footnote{Метод Ньютона не всегда приводит к
решению, но можно показать, что в удачных случаях каждая итерация
удваивает точность приближения в терминах количества цифр после
запятой. Для таких случаев метод Ньютона сходится гораздо быстрее, чем
метод половинного деления.}

Чтобы реализовать метод Ньютона в виде процедуры, сначала нужно
выразить понятие производной. Заметим, что <<взятие производной>>,
подобно торможению усреднением, трансформирует одну функцию в другую.
Например, производная функции @math{x \mapsto x^3} есть функция
@math{x \mapsto 3x^2}. В общем случае, если @math{g} есть функция, а
@math{dx} --- маленькое число, то производная @math{Dg} функции @math{g}
есть функция, значение которой в каждой точке @math{x} описывается
формулой (при @math{dx}, стремящемся к нулю)
@ifinfo

@example
        g(x + dx) - g(x)
Dg(x) = ----------------
               dx
@end example

@end ifinfo
@tex
$$ {Dg(x)} = {g(x + {\it dx}) - g(x) \over {\it dx}}\,. $$
@end tex
@noindent
Таким образом, мы можем выразить понятие производной (взяв @math{dx}
равным, например, 0.00001) в виде процедуры

@lisp
(define (deriv g)
  (lambda (x) (/ (- (g (+ x dx)) (g x)) dx)))
@end lisp

@noindent
дополненной определением

@lisp
(define dx 0.00001)
@end lisp

@noindent
Подобно @code{average-damp}, @code{deriv} является процедурой, которая
берет процедуру в качестве аргумента и возвращает процедуру как
значение. Например, чтобы найти приближенное значение производной
@math{x \mapsto x^3} в точке 5 (точное значение производной равно 75),
можно вычислить

@lisp
(define (cube x) (* x x x))
((deriv cube) 5)
@i{75.00014999664018}
@end lisp

@noindent
С помощью @code{deriv} мы можем выразить метод Ньютона как процесс
поиска неподвижной точки:

@lisp
(define (newton-transform g)
  (lambda (x) (- x (/ (g x) ((deriv g) x)))))
(define (newtons-method g guess)
  (fixed-point (newton-transform g) guess))
@end lisp

@noindent
Процедура @code{newton-transform} выражает формулу, приведенную в начале
этого раздела, а @code{newtons-method} легко определяется с ее
помощью. В качестве аргументов она принимает процедуру, вычисляющую
функцию, чей ноль мы хотим найти, а также начальное значение
приближения. Например, чтобы найти квадратный корень @math{x}, мы
можем с помощью метода Ньютона найти ноль функции
@math{y \mapsto y^2 - x}, начиная со значения 1.@footnote{При поиске
квадратных корней метод Ньютона быстро сходится к правильному решению,
начиная с любой точки.} Это дает нам еще одну форму процедуры
вычисления квадратного корня:

@lisp
(define (sqrt x)
  (newtons-method
   (lambda (y) (- (square y) x)) 1.0))
@end lisp

@subsubheading Abstractions and first-class procedures

Абстракции и процедуры как полноправные объекты
Мы видели два способа представить вычисление квадратного корня как
частный случай более общего метода; один раз это был поиск неподвижной
точки, другой --- метод Ньютона. Поскольку сам метод Ньютона был
выражен как процесс поиска неподвижной точки, на самом деле мы увидели
два способа вычислить квадратный корень как неподвижную точку. Каждый из
этих методов получает некоторую функцию и находит неподвижную точку для
некоторой трансформации этой функции. Эту общую идею мы можем выразить
как процедуру:

@lisp
(define (fixed-point-of-transform g transform guess)
  (fixed-point (transform g) guess))
@end lisp

@noindent
Эта очень общая процедура принимает в качестве аргументов процедуру
@code{g}, которая вычисляет некоторую функцию, процедуру, которая
трансформирует @code{g}, и начальное приближение. Возвращаемое значение
есть неподвижная точка трансформированной функции.

С помощью такой абстракции можно переформулировать процедуру вычисления
квадратного корня из этого раздела (ту, где мы ищем неподвижную точку
версии @math{y \mapsto x / y}, заторможенной усреднением) как частный
случай общего метода:

@lisp
(define (sqrt x)
  (fixed-point-of-transform
   (lambda (y) (/ x y)) average-damp 1.0))
@end lisp

@noindent
Подобным образом, вторую процедуру нахождения квадратного корня из этого
раздела (пример применения метода Ньютона, который находит неподвижную
точку Ньютонова преобразования @math{y \mapsto y^2 - x}) можно
представить так:

@lisp
(define (sqrt x)
  (fixed-point-of-transform
   (lambda (y) (- (square y) x)) newton-transform 1.0))
@end lisp

@noindent
Мы начали раздел @ref{1.3}
с наблюдения, что составные процедуры являются важным механизмом
абстракции, поскольку они позволяют выражать общие методы вычисления в
виде явных элементов нашего языка программирования. Теперь мы увидели,
как процедуры высших порядков позволяют нам манипулировать этими общими
методами и создавать еще более глубокие абстракции.

Как программисты, мы должны быть готовы распознавать возможности поиска
абстракций, лежащих в основе наших программ, строить нашу работу на
таких абстракциях и обобщать их, создавая еще более мощные абстракции.
Это не значит, что программы всегда нужно писать на возможно более
глубоком уровне абстракции: опытные программисты умеют выбирать тот
уровень, который лучше всего подходит к их задаче. Однако важно быть
готовыми мыслить в терминах этих абстракций и быть готовым применить
их в новых контекстах. Важность процедур высшего порядка состоит в
том, что они позволяют нам явно представлять эти абстракции в качестве
элементов нашего языка программирования, так что мы можем обращаться с
ними так же, как и с другими элементами вычисления.

В общем случае языки программирования накладывают ограничения на
способы, с помощью которых можно манипулировать элементами вычисления.
Говорят, что элементы, на которые накладывается наименьшее число
ограничений, имеют статус элементов вычисления (@newterm{first-class}) или . Вот
некоторые из их <<прав и привилегий>>:@footnote{Понятием полноправного
статуса элементов языка программирования мы обязаны британскому
специалисту по информатике Кристоферу Стрейчи (1916-1975).}

@itemize @bullet

@item
Их можно называть с помощью переменных.

@item
Их можно передавать в процедуры в качестве аргументов.

@item
Их можно возвращать из процедур в виде результата.

@item
Их можно включать в структуры данных.@footnote{Примеры этого мы увидим
после того, как введем понятие структур данных в @ref{Глава 2}.}

@end itemize

@noindent
Лисп, в отличие от других распространенных языков программирования,
дает процедурам полноправный статус. Это может быть проблемой для
эффективной реализации, но зато получаемый выигрыш в выразительной силе
огромен.@footnote{Основная цена, которую реализации приходится платить за
придание процедурам статуса полноправных объектов, состоит в том, что,
поскольку мы разрешаем возвращать процедуры как значения, нам нужно
оставлять память для хранения свободных переменных процедуры даже тогда,
когда она не выполняется. В реализации Scheme, которую мы рассмотрим в
разделе @ref{4.1}, эти переменные хранятся в окружении процедуры.}

@quotation
@strong{@anchor{Упражнение 1.40}Упражнение 1.40:} Определите процедуру @code{cubic}, которую можно было бы
использовать совместно с процедурой @code{newtons-method} в выражениях
вида

@lisp
(newtons-method (cubic a b c) 1)
@end lisp

@noindent
для приближенного вычисления нулей кубических уравнений @math{x^3 + ax^2 + bx + c}.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.41}Упражнение 1.41:} Определите процедуру
@code{double}, которая принимает как
аргумент процедуру с одним аргументом и возвращает процедуру, которая
применяет исходную процедуру дважды. Например, если процедура @code{inc}
добавляет к своему аргументу 1, то @code{(double inc)} должна быть
процедурой, которая добавляет 2. Скажите, какое значение возвращает

@lisp
(((double (double double)) inc) 5)
@end lisp
@end quotation

@quotation
@strong{@anchor{Упражнение 1.42}Упражнение 1.42:} Пусть @math{f} и
@math{g} --- две одноаргументные функции.
По определению, (@newterm{composition}) @math{f} и @math{g} есть функция
@math{x \mapsto f(g(x))}. Определите процедуру @code{compose} которая
реализует композицию. Например, если @code{inc} --- процедура,
добавляющая к своему аргументу 1,

@lisp
((compose square inc) 6)
@i{49}
@end lisp
@end quotation

@quotation
@strong{@anchor{Упражнение 1.43}Упражнение 1.43:} Если @math{f}
есть численная функция, а @math{n} ---
положительное целое число, то мы можем построить @math{n}-кратное
применение @math{f}, которое определяется как функция, значение
которой в точке @math{x} равно @math{f(f( \dots (f(x)) \dots ))}.
Например, если @math{f} есть функция @math{x \mapsto x + 1}, то
@math{n}-кратным применением @math{f} будет функция
@math{x \mapsto x + n}. Если @math{f} есть операция возведения в
квадрат, то @math{n}-кратное применение @math{f} есть функция, которая
возводит свой аргумент в @math{2^n}-ю степень. Напишите процедуру,
которая принимает в качестве ввода процедуру, вычисляющую @math{f}, и
положительное целое @math{n}, и возвращает процедуру, вычисляющую
@math{n}-кратное применение @math{f}. Требуется, чтобы Вашу процедуру
можно было использовать в таких контекстах:

@lisp
((repeated square 2) 5)
@i{625}
@end lisp

Подсказка: может оказаться удобно использовать @code{compose} из
упражнения @ref{Упражнение 1.42}.
@end quotation

@quotation
@strong{@anchor{Упражнение 1.44}Упражнение 1.44:} Идея (@newterm{smoothing a function}) играет важную роль в обработке
сигналов. Если @math{f} --- функция, а @math{dx} --- некоторое малое
число, то сглаженная версия @math{f} есть функция, значение которой в
точке @math{x} есть среднее между @math{f (x-dx)}, @math{f(x)} и
@math{f
(x+dx)}. Напишите процедуру @code{smooth}, которая в качестве ввода
принимает процедуру, вычисляющую @math{f}, и возвращает процедуру,
вычисляющую сглаженную версию @math{f}. Иногда бывает удобно проводить
повторное сглаживание (то есть сглаживать сглаженную функцию и т.д.),
получая (n-fold smoothed function). Покажите, как породить
@math{n}-кратно сглаженную функцию с помощью @code{smooth} и
@code{repeated} из упражнения @ref{Упражнение 1.43}.

@end quotation

@quotation
@strong{@anchor{Упражнение 1.45}Упражнение 1.45:} В разделе @ref{1.3.3} мы
видели, что попытка вычисления квадратных корней путем наивного поиска
неподвижной точки @math{y \mapsto x / y} не сходится, и что это можно
исправить путем торможения усреднением. Тот же самый метод работает для
нахождения кубического корня как неподвижной точки @math{y \mapsto x / y^2},
заторможенной усреднением. К сожалению, этот процесс не
работает для корней четвертой степени --- однажды примененного
торможения усреднением недостаточно, чтобы заставить сходиться процесс
поиска неподвижной точки @math{y \mapsto x / y^3}.
С другой стороны, если мы применим торможение усреднением дважды
(т.е. применим торможение усреднением к результату торможения
усреднением от @math{y \mapsto x / y^3}), то поиск неподвижной точки
начнет сходиться. Проделайте эксперименты, чтобы понять, сколько
торможений усреднением нужно, чтобы вычислить корень @math{n}-ой степени
как неподвижную точку на основе многократного торможения усреднением
функции @math{y \mapsto x / y^{n-1}}.
Используя свои результаты для того, напишите простую процедуру
вычислениякорней @math{n}-ой степени с помощью процедур
@code{fixed-point}, @code{average-damp} и @code{repeated} из
упражнения @ref{Упражнение 1.43}. Считайте, что все арифметические
операции, какие Вам понадобятся, присутствуют в языке как примитивы.
@end quotation

@endpage
@quotation
@strong{@anchor{Упражнение 1.46}Упражнение 1.46:} Некоторые из
вычислительных методов, описанных в этой
главе, являются примерами чрезвычайно общей вычислительной стратегии,
называемой (@newterm{iterative improvement}). Пошаговое улучшение состоит в
следующем: чтобы что-то вычислить, нужно взять какое-то начальное
значение, проверить, достаточно ли оно хорошо, чтобы служить ответом, и
если нет, то улучшить это значение и продолжить процесс с новым
значением. Напишите процедуру @code{iterative-improve}, которая
принимает в качестве аргументов две процедуры: проверку, достаточно ли
хорошо значение, и метод улучшения значения. @code{Iterative-improve}
должна возвращать процедуру, которая принимает начальное значение в
качестве аргумента и улучшает его, пока оно не станет достаточно
хорошим. Перепишите процедуру @code{sqrt} из раздела @ref{1.1.7} и
процедуру @code{fixed-point} из раздела @ref{1.3.3} в терминах
@code{iterative-improve}.
@end quotation

